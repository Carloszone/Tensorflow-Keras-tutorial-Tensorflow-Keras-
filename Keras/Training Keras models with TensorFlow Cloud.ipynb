{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b518b04cbfe0"
   },
   "source": [
    "##### Copyright 2020 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2021-01-20T19:58:21.820021Z",
     "iopub.status.busy": "2021-01-20T19:58:21.819341Z",
     "iopub.status.idle": "2021-01-20T19:58:21.821447Z",
     "shell.execute_reply": "2021-01-20T19:58:21.821871Z"
    },
    "id": "906e07f6e562"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c359f002e834"
   },
   "source": [
    "# Training Keras models with TensorFlow Cloud\n",
    "# 用TensorFlow云服务来训练Keras模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b1c0246f8536"
   },
   "source": [
    "## Introduction\n",
    "## 简介\n",
    "\n",
    "\n",
    "[TensorFlow Cloud](https://github.com/tensorflow/cloud) is a Python package that\n",
    "provides APIs for a seamless transition from local debugging to distributed training\n",
    "in Google Cloud. It simplifies the process of training TensorFlow models on the\n",
    "cloud into a single, simple function call, requiring minimal setup and no changes\n",
    "to your model. TensorFlow Cloud handles cloud-specific tasks such as creating VM\n",
    "instances and distribution strategies for your models automatically. This guide\n",
    "will demonstrate how to interface with Google Cloud through TensorFlow Cloud,\n",
    "and the wide range of functionality provided within TensorFlow Cloud. We'll start\n",
    "with the simplest use-case.\n",
    "\n",
    "[TensorFlow Cloud](https://github.com/tensorflow/cloud) 是一个python包，其提供了一系列APIs来实现从本地调试到在Google云服务上进行分布式训练的无缝过渡。TensorFlow云服务将TensorFlow模型在云上的训练过程简化为一个单独的，简单的函数调用。只需要少量的设置且不需要对你的模型进行任何改变。TensorFlow云服务可以胜任很多具体的云计算任务，比如创建虚拟机实例和自动化模型的分布式策略。这个指南将会演示如何通过TensorFlow云服务来与Google云服务进行交互，以及TensorFlow云服务其他功能。我们将从一个最简单的使用案例开始"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e015c75faba2"
   },
   "source": [
    "## Setup\n",
    "## 环境设定\n",
    "\n",
    "We'll get started by installing TensorFlow Cloud, and importing the packages we\n",
    "will need in this guide.\n",
    "\n",
    "我们首先需要安装TensorFlow Cloud，并导入我们在这篇指南中所需要的所有的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-20T19:58:21.835398Z",
     "iopub.status.busy": "2021-01-20T19:58:21.832036Z",
     "iopub.status.idle": "2021-01-20T19:58:28.695321Z",
     "shell.execute_reply": "2021-01-20T19:58:28.694511Z"
    },
    "id": "99e5bc5e0ab8"
   },
   "outputs": [],
   "source": [
    "!pip install -q tensorflow_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-20T19:58:28.701252Z",
     "iopub.status.busy": "2021-01-20T19:58:28.700439Z",
     "iopub.status.idle": "2021-01-20T19:58:36.259517Z",
     "shell.execute_reply": "2021-01-20T19:58:36.258753Z"
    },
    "id": "26113effabca"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_cloud as tfc\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API overview: a first end-to-end example\n",
    "## API概念：第一个端到端示例\n",
    "\n",
    "Let's begin with a Keras model training script, such as the following CNN:\n",
    "让我们从一个Keras模型的训练脚本来事，比如接下来的CNN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e8568395c87b"
   },
   "outputs": [],
   "source": [
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(28, 28)),\n",
    "        # Use a Rescaling layer to make sure input values are in the [0, 1] range.\n",
    "        layers.experimental.preprocessing.Rescaling(1.0 / 255),\n",
    "        # The original images have shape (28, 28), so we reshape them to (28, 28, 1)\n",
    "        layers.Reshape(target_shape=(28, 28, 1)),\n",
    "        # Follow-up with a classic small convnet\n",
    "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "        layers.MaxPooling2D(2),\n",
    "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "        layers.MaxPooling2D(2),\n",
    "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dense(10),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=keras.metrics.SparseCategoricalAccuracy(),\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=20, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "514f51a9a45d"
   },
   "source": [
    "To train this model on Google Cloud we just need to add a call to `run()` at\n",
    "the beginning of the script, before the imports:\n",
    "\n",
    "要在Google云服务上训练这个模型，我们需要在脚本的开头，在导入之前加入对 `run()`的调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfc.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6e38288bb617"
   },
   "source": [
    "You don't need to worry about cloud-specific tasks such as creating VM instances\n",
    "and distribution strategies when using TensorFlow Cloud.\n",
    "The API includes intelligent defaults for all the parameters -- everything is\n",
    "configurable, but many models can rely on these defaults.\n",
    "\n",
    "你不需要担心具体的云端任务，比如创建虚拟机以及使用TensorFlow云时的分布式策略。这个API包含了所有参数的智能默认设定。所有的一切都是可设置的，不过很多模型只需要依赖默认设定就好\n",
    "\n",
    "Upon calling `run()`, TensorFlow Cloud will:\n",
    "\n",
    "- Make your Python script or notebook distribution-ready.\n",
    "- Convert it into a Docker image with required dependencies.\n",
    "- Run the training job on a GCP GPU-powered VM.\n",
    "- Stream relevant logs and job information.\n",
    "\n",
    "在调用`run()`时，TensorFlow将会：\n",
    "- 将你的Python脚本或笔记本做好发布准备.\n",
    "- 将你的Python脚本或笔记本转换为具有依赖性的Docker镜像.\n",
    "- 在一个 GCP GPU-powered虚拟机上执行训练工作.\n",
    "- 返回相关日志和工作信息.\n",
    "\n",
    "The default VM configuration is 1 chief and 0 workers with 8 CPU cores and\n",
    "1 Tesla T4 GPU.\n",
    "\n",
    "虚拟机的默认设置是1个chief和0个worker，8核CPU和1个Tesla T4 GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ab860e037c9"
   },
   "source": [
    "## Google Cloud configuration\n",
    "## Google云设置\n",
    "In order to facilitate the proper pathways for Cloud training, you will need to\n",
    "do some first-time setup. If you're a new Google Cloud user, there are a few\n",
    "preliminary steps you will need to take:\n",
    "\n",
    "1. Create a GCP Project;\n",
    "2. Enable AI Platform Services;\n",
    "3. Create a Service Account;\n",
    "4. Download an authorization key;\n",
    "5. Create a Cloud Storage bucket.\n",
    "\n",
    "Detailed first-time setup instructions can be found in the\n",
    "[TensorFlow Cloud README](https://github.com/tensorflow/cloud#setup-instructions),\n",
    "and an additional setup example is shown on the\n",
    "[TensorFlow Blog](https://blog.tensorflow.org/2020/08/train-your-tensorflow-model-on-google.html).\n",
    "\n",
    "为了提升云端训练的效率，你需要做一些首次设置。如果你是Google云服务的新用户，这里是一些你需要完成的基本步骤：\n",
    "\n",
    "1. 创建一个GCP项目\n",
    "2. 启动AI平台服务\n",
    "3. 创建一个服务账号\n",
    "4. 下载授权密钥\n",
    "5. 创建一个云储存桶(bucket)\n",
    "\n",
    "\n",
    "## Common workflows and Cloud storage\n",
    "## 常规流程和云储存\n",
    "\n",
    "In most cases, you'll want to retrieve your model after training on Google Cloud.\n",
    "For this, it's crucial to redirect saving and loading to Cloud Storage while\n",
    "training remotely. We can direct TensorFlow Cloud to our Cloud Storage bucket for\n",
    "a variety of tasks. The storage bucket can be used to save and load large training\n",
    "datasets, store callback logs or model weights, and save trained model files.\n",
    "To begin, let's configure `fit()` to save the model to a Cloud Storage, and set\n",
    "up TensorBoard monitoring to track training progress.\n",
    "\n",
    "在大多数情况下，你会需要在Google云上完成训练后再次检索你的模型。为此，在远程训练时，重新定向到云储存空间进行保存和加载至关重要。我们可以将TensorFlow云引导至我们的云储存桶来完成大部分任务。云储存桶可以被用于保存和加载大量训练数据集，保存回调函数的日志和模型权重，以及保存训练后的模型文件。首先，让我们以设置`fit()`方法来保存模型到云储存，然后设置TensorBoard监控来跟踪训练进度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-20T19:58:36.269573Z",
     "iopub.status.busy": "2021-01-20T19:58:36.268451Z",
     "iopub.status.idle": "2021-01-20T19:58:36.270426Z",
     "shell.execute_reply": "2021-01-20T19:58:36.270880Z"
    },
    "id": "af5077731187"
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=(28, 28)),\n",
    "            layers.experimental.preprocessing.Rescaling(1.0 / 255),\n",
    "            layers.Reshape(target_shape=(28, 28, 1)),\n",
    "            layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "            layers.MaxPooling2D(2),\n",
    "            layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "            layers.MaxPooling2D(2),\n",
    "            layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(128, activation=\"relu\"),\n",
    "            layers.Dense(10),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=keras.metrics.SparseCategoricalAccuracy(),\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5f2e65d8f3a6"
   },
   "source": [
    "Let's save the TensorBoard logs and model checkpoints generated during training\n",
    "in our cloud storage bucket.\n",
    "\n",
    "让我们保存训练期间产生的TensorBoard日志和模型检查点信息到我们的云端储存桶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-20T19:58:36.982158Z",
     "iopub.status.busy": "2021-01-20T19:58:36.981255Z",
     "iopub.status.idle": "2021-01-20T19:58:38.213155Z",
     "shell.execute_reply": "2021-01-20T19:58:38.212560Z"
    },
    "id": "fdc4f951281c"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "\n",
    "# Note: Please change the gcp_bucket to your bucket name.\n",
    "# 注意，请将gcp_bucket替换为你的储存桶名称\n",
    "gcp_bucket = \"keras-examples\"\n",
    "\n",
    "checkpoint_path = os.path.join(\"gs://\", gcp_bucket, \"mnist_example\", \"save_at_{epoch}\")\n",
    "\n",
    "tensorboard_path = os.path.join(  # Timestamp included to enable timeseries graphs 包含时间戳，以启用时间序列图\n",
    "    \"gs://\", gcp_bucket, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    # TensorBoard will store logs for each epoch and graph performance for us. TensorBoard将会为我们保存每一次训练的日志并绘制性能图\n",
    "    keras.callbacks.TensorBoard(log_dir=tensorboard_path, histogram_freq=1),\n",
    "    # ModelCheckpoint will save models after each epoch for retrieval later. ModelCheckpoint将会在每次训练后保存模型供之后使用\n",
    "    keras.callbacks.ModelCheckpoint(checkpoint_path),\n",
    "    # EarlyStopping will terminate training when val_loss ceases to improve. EarlyStopping将会在val_loss不在提升时中止训练\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3),\n",
    "]\n",
    "\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45d6210176e6"
   },
   "source": [
    "Here, we will load our data from Keras directly. In general, it's best practice\n",
    "to store your dataset in your Cloud Storage bucket, however TensorFlow Cloud can\n",
    "also accomodate datasets stored locally. That's covered in the Multi-file section\n",
    "of this guide.\n",
    "\n",
    "这里，我们将要直接从Keras加载我们的模型。通常来说，最佳实践是在你的云储存桶保存你的数据，然而TensorFlow云同样可以适应本地储存的数据集。这在本指南的多个部分都有提及。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-20T19:58:38.218895Z",
     "iopub.status.busy": "2021-01-20T19:58:38.218034Z",
     "iopub.status.idle": "2021-01-20T19:58:38.514166Z",
     "shell.execute_reply": "2021-01-20T19:58:38.514669Z"
    },
    "id": "bd4ef6ffa611"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b1d2a2688887"
   },
   "source": [
    "The [TensorFlow Cloud](https://github.com/tensorflow/cloud) API provides the\n",
    "`remote()` function to determine whether code is being executed locally or on\n",
    "the cloud. This allows for the separate designation of `fit()` parameters for\n",
    "local and remote execution, and provides means for easy debugging without overloading\n",
    "your local machine.\n",
    "\n",
    "[TensorFlow Cloud](https://github.com/tensorflow/cloud)API提供了`remote()`函数来决定代码是本地执行或云端执行。这允许在本地和远程执行中分别指定 `fit()` 参数，并提供了简便的调试而不会是你的本地设备负担过重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-20T19:58:38.520786Z",
     "iopub.status.busy": "2021-01-20T19:58:38.520040Z",
     "iopub.status.idle": "2021-01-20T19:58:56.704396Z",
     "shell.execute_reply": "2021-01-20T19:58:56.704793Z"
    },
    "id": "cfab9ff41fd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 6s 3ms/step - loss: 0.4867 - sparse_categorical_accuracy: 0.8556\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0638 - sparse_categorical_accuracy: 0.9796\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0411 - sparse_categorical_accuracy: 0.9870\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0333 - sparse_categorical_accuracy: 0.9895\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0278 - sparse_categorical_accuracy: 0.9910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa57866c4e0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if tfc.remote():\n",
    "    epochs = 100\n",
    "    callbacks = callbacks\n",
    "    batch_size = 128\n",
    "else:\n",
    "    epochs = 5\n",
    "    batch_size = 64\n",
    "    callbacks = None\n",
    "\n",
    "model.fit(x_train, y_train, epochs=epochs, callbacks=callbacks, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9b27c0b3b7db"
   },
   "source": [
    "Let's save the model in GCS after the training is complete.\n",
    "\n",
    "让我们在训练完成后将模型保存在GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-20T19:58:56.710268Z",
     "iopub.status.busy": "2021-01-20T19:58:56.709299Z",
     "iopub.status.idle": "2021-01-20T19:58:56.712235Z",
     "shell.execute_reply": "2021-01-20T19:58:56.711658Z"
    },
    "id": "b00451dcfeab"
   },
   "outputs": [],
   "source": [
    "save_path = os.path.join(\"gs://\", gcp_bucket, \"mnist_example\")\n",
    "\n",
    "if tfc.remote():\n",
    "    model.save(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0dceb5b7a173"
   },
   "source": [
    "We can also use this storage bucket for Docker image building, instead of your local\n",
    "Docker instance. For this, just add your bucket to the `docker_image_bucket_name` parameter.\n",
    "\n",
    "我们同样可以用储存桶替代你的本地Docker实例，来奖励Docker镜像。要这么多的话，将你的储存桶添加至`docker_image_bucket_name`参数中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "13200523ed93"
   },
   "outputs": [],
   "source": [
    "# docs_infra: no_execute\n",
    "tfc.run(docker_image_bucket_name=gcp_bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "060a2112c34e"
   },
   "source": [
    "After training the model, we can load the saved model and view our TensorBoard logs\n",
    "to monitor performance.\n",
    "\n",
    "在训练模型之后，我们可以加载保存的模型并浏览我们的TensorBoard日志来查看表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "b8d773e2cfb7"
   },
   "outputs": [],
   "source": [
    "# docs_infra: no_execute\n",
    "model = keras.models.load_model(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "05d1d68bae5a"
   },
   "outputs": [],
   "source": [
    "!#docs_infra: no_execute\n",
    "!tensorboard dev upload --logdir \"gs://keras-examples-jonah/logs/fit\" --name \"Guide MNIST\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3785ece03a8f"
   },
   "source": [
    "## Large-scale projects\n",
    "## 大规模项目\n",
    "\n",
    "In many cases, your project containing a Keras model may encompass more than one\n",
    "Python script, or may involve external data or specific dependencies. TensorFlow\n",
    "Cloud is entirely flexible for large-scale deployment, and provides a number of\n",
    "intelligent functionalities to aid your projects.\n",
    "\n",
    "在很多情况下，你的项目有一个包含了数个Python脚本的Keras模型，或者涉及到外部数据或特定的依赖关系。TensorFlow云对于大规模部署工作非常灵活，并提供了一系列智能功能来帮助你的项目。\n",
    "\n",
    "### Entry points: support for Python scripts and Jupyter notebooks\n",
    "### 进入点：支持Python脚本和Jupyter笔记本\n",
    "\n",
    "Your call to the `run()` API won't always be contained inside the same Python script\n",
    "as your model training code. For this purpose, we provide an `entry_point` parameter.\n",
    "The `entry_point` parameter can be used to specify the Python script or notebook in\n",
    "which your model training code lives. When calling `run()` from the same script as\n",
    "your model, use the `entry_point` default of `None`.\n",
    "\n",
    "你对`run()` API 的调用并不总是包含在同一个Python脚本或者模型训练代码之中。为此，我们提供了 `entry_point`参数。这个参数可以用于指定包含训练代码的Python脚本或者笔记本。当从同一个脚本中调用`run()`，使用`entry_point`的默认设置`None`\n",
    "\n",
    "### `pip` dependencies\n",
    "###  `pip` 依赖性\n",
    "\n",
    "If your project calls on additional `pip` dependencies, it's possible to specify\n",
    "the additional required libraries by including a `requirements.txt` file. In this\n",
    "file, simply put a list of all the required dependencies and TensorFlow Cloud will\n",
    "handle integrating these into your cloud build.\n",
    "\n",
    "如果你的项目调用了额外的 `pip`依赖性，通过一个`requirements.txt` 文件来指定额外的所需要的库也是可行的。在这个文件中，你只需要放入你所需要的依赖性库列表，TensorFlow云将会将这些集成到你的云端建模中\n",
    "\n",
    "### Python notebooks\n",
    "### Pythonb笔记本\n",
    "\n",
    "TensorFlow Cloud is also runnable from Python notebooks. Additionally, your specified\n",
    "`entry_point` can be a notebook if needed. There are two key differences to keep\n",
    "in mind between TensorFlow Cloud on notebooks compared to scripts:\n",
    "\n",
    "- When calling `run()` from within a notebook, a Cloud Storage bucket must be specified\n",
    "for building and storing your Docker image.\n",
    "- GCloud authentication happens entirely through your authentication key, without\n",
    "project specification. An example workflow using TensorFlow Cloud from a notebook\n",
    "is provided in the \"Putting it all together\" section of this guide.\n",
    "\n",
    "TensorFlow云同样可以从Python笔记本中运行。此外，你可以指定`entry_point`为笔记本，如果需要的话。笔记本上的TensorFlow Cloud和脚本中的TensorFlow Cloud 有两处关键性的不同：\n",
    "\n",
    "- 当从笔记本中调用`run()` 时，, 云储存桶必须被指定以用来建立和保存你的Docker镜像\n",
    "\n",
    "- GCloud 认证完全通过你的密钥进行,没有项目可以例外。本指南的“组合”部分提供了一个从笔记本中运行TensorFlow Cloud的示例\n",
    "\n",
    "\n",
    "### Multi-file projects\n",
    "### 多文件项目\n",
    "\n",
    "If your model depends on additional files, you only need to ensure that these files\n",
    "live in the same directory (or subdirectory) of the specified entry point. Every file\n",
    "that is stored in the same directory as the specified `entry_point` will be included\n",
    "in the Docker image, as well as any files stored in subdirectories adjacent to the\n",
    "`entry_point`. This is also true for dependencies you may need which can't be acquired\n",
    "through `pip`\n",
    "\n",
    "如果你的模型依赖额外的文件，你只需要确保这些文件在同一个目录或子目录就可以指定进入点。每一个保存在同一目录下的文件都会与特定的“进入点”一起被包含在Docker镜像中，对于任何保存在子目录中的文件也是如此。这同样适用于你需要的且不需要通过`pip`获得的依赖性\n",
    "\n",
    "For an example of a custom entry-point and multi-file project with additional pip\n",
    "dependencies, take a look at this multi-file example on the\n",
    "[TensorFlow Cloud Repository](https://github.com/tensorflow/cloud/tree/master/src/python/tensorflow_cloud/core/tests/examples/multi_file_example).\n",
    "\n",
    "自定义进入点示例，多文件项目示例以及额外pip依赖性案例，请参考[这里](https://github.com/tensorflow/cloud/tree/master/src/python/tensorflow_cloud/core/tests/examples/multi_file_example).\n",
    "\n",
    "For brevity, we'll just include the example's `run()` call:\n",
    "\n",
    "简洁起见，我们将展示只包含`run()`调用的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfc.run(\n",
    "    docker_image_bucket_name=gcp_bucket,\n",
    "    entry_point=\"train_model.py\",\n",
    "    requirements=\"requirements.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "997e3f89c734"
   },
   "source": [
    "## Machine configuration and distributed training\n",
    "## 机器设置和分布式训练\n",
    "\n",
    "Model training may require a wide range of different resources, depending on the\n",
    "size of the model or the dataset. When accounting for configurations with multiple\n",
    "GPUs, it becomes critical to choose a fitting\n",
    "[distribution strategy](https://www.tensorflow.org/guide/distributed_training).\n",
    "Here, we outline a few possible configurations:\n",
    "\n",
    "模型训练可能会需要大范围的不同的资源。这取决于模型或数据集的规模。当考虑到有多个GPU时，选择合适的[分布式策略](https://www.tensorflow.org/guide/distributed_training)至关重要。\n",
    "这里我们概述了一些可能的设置：\n",
    "\n",
    "### Multi-worker distribution\n",
    "### 多工作器分布\n",
    "Here, we can use `COMMON_MACHINE_CONFIGS` to designate 1 chief CPU and 4 worker GPUs.\n",
    "\n",
    "这里我们使用e `COMMON_MACHINE_CONFIGS`来分配一个主要cpu和4个工作GPU\n",
    "\n",
    "```python\n",
    "tfc.run(\n",
    "    docker_image_bucket_name=gcp_bucket,\n",
    "    chief_config=tfc.COMMON_MACHINE_CONFIGS['CPU'],\n",
    "    worker_count=2,\n",
    "    worker_config=tfc.COMMON_MACHINE_CONFIGS['T4_4X']\n",
    ")\n",
    "```\n",
    "By default, TensorFlow Cloud chooses the best distribution strategy for your machine\n",
    "configuration with a simple formula using the `chief_config`, `worker_config` and\n",
    "`worker_count` parameters provided.\n",
    "\n",
    "- If the number of GPUs specified is greater than zero, `tf.distribute.MirroredStrategy` will be chosen.\n",
    "- If the number of workers is greater than zero, `tf.distribute.experimental.MultiWorkerMirroredStrategy` or `tf.distribute.experimental.TPUStrategy` will be chosen based on the accelerator type.\n",
    "- Otherwise, `tf.distribute.OneDeviceStrategy` will be chosen.\n",
    "\n",
    "默认设置下，TensorFlow Cloud通过一个简单的公式（基于提供的`chief_config`, `worker_config` and`worker_count`参数）来为你的机器设置选择最佳分布策略：\n",
    "- 如果指定的GPU数量大于0，选择`tf.distribute.MirroredStrategy`\n",
    "- 如果工作器数量大于0，基于加速类型选择 `tf.distribute.experimental.MultiWorkerMirroredStrategy`或者 `tf.distribute.experimental.TPUStrategy` .\n",
    "- 其他情况下,选择 `tf.distribute.OneDeviceStrategy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0d938efab72"
   },
   "source": [
    "### TPU distribution\n",
    "### TPU 分布\n",
    "\n",
    "Let's train the same model on TPU, as shown:\n",
    "\n",
    "让我们用TPU训练同一个模型，其代码如下：\n",
    "```python\n",
    "tfc.run(\n",
    "    docker_image_bucket_name=gcp_bucket,\n",
    "    chief_config=tfc.COMMON_MACHINE_CONFIGS[\"CPU\"],\n",
    "    worker_count=1,\n",
    "    worker_config=tfc.COMMON_MACHINE_CONFIGS[\"TPU\"]\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1dec83a0b19"
   },
   "source": [
    "### Custom distribution strategy\n",
    "### 自定义分布策略\n",
    "To specify a custom distribution strategy, format your code normally as you would\n",
    "according to the\n",
    "[distributed training guide](https://www.tensorflow.org/guide/distributed_training)\n",
    "and set `distribution_strategy` to `None`. Below, we'll specify our own distribution\n",
    "strategy for the same MNIST model.\n",
    "\n",
    "要指定自定义分布式策略，根据[分布式策略指南](https://www.tensorflow.org/guide/distributed_training)将你的代码格式化并将`distribution_strategy`设置为 `None`。下面我们将为同一个MNIST模型指定我们的分布式策略\n",
    "\n",
    "```python\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "with mirrored_strategy.scope():\n",
    "  model = create_model()\n",
    "\n",
    "if tfc.remote():\n",
    "    epochs = 100\n",
    "    batch_size = 128\n",
    "else:\n",
    "    epochs = 10\n",
    "    batch_size = 64\n",
    "    callbacks = None\n",
    "\n",
    "model.fit(\n",
    "    x_train, y_train, epochs=epochs, callbacks=callbacks, batch_size=batch_size\n",
    ")\n",
    "\n",
    "tfc.run(\n",
    "    docker_image_bucket_name=gcp_bucket,\n",
    "    chief_config=tfc.COMMON_MACHINE_CONFIGS['CPU'],\n",
    "    worker_count=2,\n",
    "    worker_config=tfc.COMMON_MACHINE_CONFIGS['T4_4X'],\n",
    "    distribution_strategy=None\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0a50b62bf672"
   },
   "source": [
    "## Custom Docker images\n",
    "## 自定义Docker镜像\n",
    "\n",
    "By default, TensorFlow Cloud uses a\n",
    "[Docker base image](https://hub.docker.com/r/tensorflow/tensorflow/)\n",
    "supplied by Google and corresponding to your current TensorFlow version. However,\n",
    "you can also specify a custom Docker image to fit your build requirements, if necessary.\n",
    "For this example, we will specify the Docker image from an older version of TensorFlow:\n",
    "\n",
    "默认情况下，TensorFlow Cloud根据你的TensorFlow 版本使用受Google支持的[Docker基本镜像](https://hub.docker.com/r/tensorflow/tensorflow/)。然而在必要情况下，你依然可以指定一个自定义Docker镜像来满足你的构建需求。在这个示例中，我们将从旧版本的TensorFlow中指定Docker镜像\n",
    "\n",
    "```python\n",
    "tfc.run(\n",
    "    docker_image_bucket_name=gcp_bucket,\n",
    "    base_docker_image=\"tensorflow/tensorflow:2.1.0-gpu\"\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bb659015ffad"
   },
   "source": [
    "## Additional metrics\n",
    "## 额外指标\n",
    "\n",
    "You may find it useful to tag your Cloud jobs with specific labels, or to stream\n",
    "your model's logs during Cloud training.\n",
    "It's good practice to maintain proper labeling on all Cloud jobs, for record-keeping.\n",
    "For this purpose, `run()` accepts a dictionary of labels up to 64 key-value pairs,\n",
    "which are visible from the Cloud build logs. Logs such as epoch performance and model\n",
    "saving internals can be accessed using the link provided by executing `tfc.run` or\n",
    "printed to your local terminal using the `stream_logs` flag.\n",
    "\n",
    "你也许会发现用特定的标签标记你的云端任务或者在云端训练期间返回你的模型日志会非常有用\n",
    "\n",
    "一个好的做法是用适当的标签来标记你所有的云端工作，以便保存记录。为了这个目的，`run()`可以接受多达64个键值对的字典型标签， 这些标签在云端日志中是可见的。像是每次的训练表现和模型保存间隔日志可以通过执行 `tfc.run`所提供的链接来访问，或者通过 `stream_logs`打印到本地\n",
    "\n",
    "```python\n",
    "job_labels = {\"job\": \"mnist-example\", \"team\": \"keras-io\", \"user\": \"jonah\"}\n",
    "\n",
    "tfc.run(\n",
    "    docker_image_bucket_name=gcp_bucket,\n",
    "    job_labels=job_labels,\n",
    "    stream_logs=True\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b34a2e8e09c3"
   },
   "source": [
    "## Putting it all together\n",
    "## 将这些组合在一起\n",
    "For an in-depth Colab which uses many of the features described in this guide,\n",
    "follow along\n",
    "[this example](https://github.com/tensorflow/cloud/blob/master/src/python/tensorflow_cloud/core/tests/examples/dogs_classification.ipynb)\n",
    "to train a state-of-the-art model to recognize dog breeds from photos using feature\n",
    "extraction.\n",
    "一个深度Colab使用了许多本指南中提到的功能，跟随这个示例训练一个最先进的模型，利用这些功能来从图片中识别狗的品种"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "training_keras_models_on_cloud.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
