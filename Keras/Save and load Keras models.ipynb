{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and load Keras models\n",
    "# 保存与加载Keras模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "## 介绍\n",
    "A Keras model consists of multiple components:\n",
    "\n",
    "1. The architecture, or configuration, which specifies what layers the model contain, and how they're connected.\n",
    "2. A set of weights values (the \"state of the model\").\n",
    "3. An optimizer (defined by compiling the model).\n",
    "4. A set of losses and metrics (defined by compiling the model or calling add_loss() or add_metric()).\n",
    "\n",
    "一个Keras模型由多个部分组成：\n",
    "1. 模型结构/设置。这个部分决定了模型包含了哪些层，以及这些层在模型内部的连接方式\n",
    "2. 一系列的权重参数（即“模型的状态”）\n",
    "3. 一个优化器（在汇编的时候加入）\n",
    "4. 一系列的损失和指标信息（在汇编的时候加入模型，也可以通过调用add_loss()和add_metric()加入）\n",
    "\n",
    "\n",
    "The Keras API makes it possible to save all of these pieces to disk at once, or to only selectively save some of them:\n",
    "\n",
    "1. Saving everything into a single archive in the TensorFlow SavedModel format (or in the older Keras H5 format). This is the standard practice.\n",
    "2. Saving the architecture / configuration only, typically as a JSON file.\n",
    "3. Saving the weights values only. This is generally used when training the model.\n",
    "\n",
    "Keras API可以让你一次性地将所有部分保存到本地，或者选择性地保存其中的某些部分：\n",
    "\n",
    "1. 常规操作：通过TensorFlow的模型保存格式（或者旧版的Keras H5格式）来将所有东西保存进一个单独的文件\n",
    "2. 只保存结构/设置部分，通常保存为JSON文件\n",
    "3. 只保存权重部分。这通常发生在训练模型的时候\n",
    "\n",
    "Let's take a look at each of these options. When would you use one or the other, and how do they work?\n",
    "\n",
    "让我们依次介绍每一个选项：你应该何时使用这种方式或那种方式，以及各个方式是怎样运作的？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to save and load a model\n",
    "## 如何保存和加载一个模型\n",
    "\n",
    "If you only have 10 seconds to read this guide, here's what you need to know.\n",
    "\n",
    "如果你时间紧迫，这部分就是你需要了解的内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "## Saving a Keras model: # 保存模型示例\n",
    "########################\n",
    "\n",
    "model = ...  # Get model (Sequential, Functional Model, or Model subclass)\n",
    "model.save('path/to/location')\n",
    "\n",
    "\n",
    "\n",
    "########################\n",
    "#Loading the model back: #加载模型示例\n",
    "########################\n",
    "\n",
    "from tensorflow import keras\n",
    "model = keras.models.load_model('path/to/location')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note 学习笔记\n",
    "\n",
    "if you have a model called \"MODEL\" ans you want to save it. use **MODEL.save('save path')** method\n",
    "\n",
    "if you want to load a model to MODEL, use **keras.models.load_model('save path')** function\n",
    "\n",
    "如果你有了一个叫“MODEL”的模型并且打算保存它，使用**MODEL.save('save path')**方法\n",
    "\n",
    "如果你要加载一个模型到“MODEL”，使用**keras.models.load_model('save path')**函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at the details.\n",
    "\n",
    "现在，让我们深入了解其中的细节"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "## 环境设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole-model saving & loading\n",
    "## 模型整体的保存与加载\n",
    "You can save an entire model to a single artifact. It will include:\n",
    "\n",
    "1. The model's architecture/config\n",
    "2. The model's weight values (which were learned during training)\n",
    "3. The model's compilation information (if compile() was called)\n",
    "4. The optimizer and its state, if any (this enables you to restart training where you left)\n",
    "\n",
    "**APIs**\n",
    "1. model.save() or tf.keras.models.save_model()\n",
    "2. tf.keras.models.load_model()\n",
    "\n",
    "如果你要保存整个模型，你需要保存的是：\n",
    "1. 模型的结构和设置\n",
    "2. 模型的权重（这是训练过程中，模型从资料中‘学到’的部分）\n",
    "3. 模型的汇编信息（如果调用过compole（）的话）\n",
    "4. 优化器及其状态，如果有的话（这可以让你从上次终端的地方重新开始训练）\n",
    "\n",
    "**API实现**\n",
    "1. 保存模型：model.save() or tf.keras.models.save_model()\n",
    "2. 加载模型：tf.keras.models.load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two formats you can use to save an entire model to disk: the TensorFlow SavedModel format, and the older Keras H5 format. The recommended format is SavedModel. It is the default when you use model.save().\n",
    "\n",
    "You can switch to the H5 format by:\n",
    "\n",
    "1. Passing save_format='h5' to save().\n",
    "2. Passing a filename that ends in .h5 or .keras to save().\n",
    "\n",
    "有两种格式可以用于保存整个模型到本地硬盘上：“SavedModel”格式和旧版”Keras H5“格式。 推荐使用“SavedModel”格式。 当你使用model.save()时，默认使用的就是“SavedModel”格式\n",
    "\n",
    "你也可以转换为H5格式：\n",
    "1. 在save()加入“save_format='h5'”。即model.save(save_format='h5')\n",
    "2. 在save()将保存的文件名后缀设置为“.h5”或“.kears”.即model.save('../user/model/model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SavedModel format\n",
    "### “SavedModel”格式\n",
    "\n",
    "SavedModel is the more comprehensive save format that saves the model architecture, weights, and the traced Tensorflow subgraphs of the call functions. This enables Keras to restore both built-in layers as well as custom objects.\n",
    "\n",
    "“SavedModel”格式是一种更为强大的保存格式。它可以保存模型的结构，权重，以及追踪调用函数的子结构。这使得Keras可以恢复内置层和自定义对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step - loss: 1.7330\n",
      "INFO:tensorflow:Assets written to: my_model\\assets\n",
      "4/4 [==============================] - 1s 2ms/step - loss: 1.5573\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24af5988130>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example\n",
    "\n",
    "def get_model():\n",
    "    # Create a simple model.\n",
    "    # 构建一个模型生成函数\n",
    "    inputs = keras.Input(shape=(32,))\n",
    "    outputs = keras.layers.Dense(1)(inputs)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "    return model\n",
    "\n",
    "\n",
    "model = get_model()\n",
    "\n",
    "# Train the model.\n",
    "# 训练这个模型\n",
    "test_input = np.random.random((128, 32))\n",
    "test_target = np.random.random((128, 1))\n",
    "model.fit(test_input, test_target)\n",
    "\n",
    "# Calling `save('my_model')` creates a SavedModel folder `my_model`.\n",
    "# 调用`save('my_model')`，创建一个'my_model'文件夹\n",
    "model.save(\"my_model\")\n",
    "\n",
    "# It can be used to reconstruct the model identically.\n",
    "# 这可以用来创建相同的模型\n",
    "reconstructed_model = keras.models.load_model(\"my_model\")\n",
    "\n",
    "# Let's check:\n",
    "# 检查两个模型是否一致\n",
    "np.testing.assert_allclose(\n",
    "    model.predict(test_input), reconstructed_model.predict(test_input)\n",
    ")\n",
    "\n",
    "# The reconstructed model is already compiled and has retained the optimizer\n",
    "# state, so training can resume:\n",
    "# 这个重建的模型已经包含了优化器和状态信息，所以训练可以继续\n",
    "reconstructed_model.fit(test_input, test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What the SavedModel contains**\n",
    "\n",
    "Calling model.save('my_model') creates a folder named my_model, containing the following:\n",
    "\n",
    "**“SavedModel”里都包含了什么**\n",
    "\n",
    "调用model.save('my_model')名字是'my_model'的文件夹，它里面包括这些东西："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 7411-1CC8\n",
      "\n",
      " Directory of C:\\Users\\carlo\\Dropbox\\NU\\Tensorflow-Keras-tutorial\\Keras\\my_model\n",
      "\n",
      "2021/04/14  02:51    <DIR>          .\n",
      "2021/04/14  02:51    <DIR>          ..\n",
      "2021/04/14  02:51    <DIR>          assets\n",
      "2021/04/14  02:51            45,971 saved_model.pb\n",
      "2021/04/14  02:51    <DIR>          variables\n",
      "               1 File(s)         45,971 bytes\n",
      "               4 Dir(s)  97,736,974,336 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls my_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model architecture, and training configuration (including the optimizer, losses, and metrics) are stored in saved_model.pb. The weights are saved in the variables/ directory.\n",
    "\n",
    "For detailed information on the SavedModel format, see [the SavedModel guide (The SavedModel format on disk).](https://www.tensorflow.org/guide/saved_model#the_savedmodel_format_on_disk)\n",
    "\n",
    "模型结构，训练设置（包含优化器，损失和指标）信息都保存在saved_model.pb。 权重保存在“variables”字典里\n",
    "\n",
    "要了解关于‘SavedModel’格式的更多信息，请参考[这里](https://www.tensorflow.org/guide/saved_model#the_savedmodel_format_on_disk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How SavedModel handles custom objects**\n",
    "**SavedModel如何处理自定义对象**\n",
    "\n",
    "When saving the model and its layers, the SavedModel format stores the class name, call function, losses, and weights (and the config, if implemented). The call function defines the computation graph of the model/layer.\n",
    "\n",
    "In the absence of the model/layer config, the call function is used to create a model that exists like the original model which can be trained, evaluated, and used for inference.\n",
    "\n",
    "Nevertheless, it is always a good practice to define the get_config and from_config methods when writing a custom model or layer class. This allows you to easily update the computation later if needed. See the section about Custom objects for more information.\n",
    "\n",
    "当保存模型和它的层时，SavedModel格式会储存类的名称，call函数，损失函数，和权重（以及设置，如果已经实现了）。call函数定义了模型/层的计算次序\n",
    "\n",
    "如果没有模型或者层设置信息，call函数会被用于创建一个和原模型相似的新模型，这个新模型同样可以被训练，评估以及用于预测\n",
    "\n",
    "然后，在构建自定义对象时，定义好get_config以及from_config方法是在编写模型和层类时的好习惯。如果需要的话，这将允许你轻松的更新之后的计算过程。要了解更多请参见之后的“自定义对象”一节"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model\\assets\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Original model: <__main__.CustomModel object at 0x0000024AF234F100>\n",
      "Model Loaded with custom objects: <__main__.CustomModel object at 0x0000024AF2696790>\n",
      "Model loaded without the custom object class: <tensorflow.python.keras.saving.saved_model.load.CustomModel object at 0x0000024AF29F76A0>\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def __init__(self, hidden_units):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.hidden_units = hidden_units\n",
    "        self.dense_layers = [keras.layers.Dense(u) for u in hidden_units]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        for layer in self.dense_layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"hidden_units\": self.hidden_units}\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "\n",
    "model = CustomModel([16, 16, 10])\n",
    "# Build the model by calling it\n",
    "# 通过调用模型类来创建模型）\n",
    "input_arr = tf.random.uniform((1, 5))\n",
    "outputs = model(input_arr)\n",
    "model.save(\"my_model\") # 保存了这个模型\n",
    "\n",
    "# Option 1: Load with the custom_object argument.\n",
    "# 选择2： 加载模型，同时也加载了自定义对象的参数\n",
    "loaded_1 = keras.models.load_model(\n",
    "    \"my_model\", custom_objects={\"CustomModel\": CustomModel}\n",
    ")\n",
    "\n",
    "# Option 2: Load without the CustomModel class.\n",
    "# 选项2： 值加载模型，不加载自定义对象的参数\n",
    "\n",
    "# Delete the custom-defined model class to ensure that the loader does not have\n",
    "# access to it.\n",
    "# 删除自定义层类来确保加载的时候不会访问它\n",
    "del CustomModel\n",
    "\n",
    "loaded_2 = keras.models.load_model(\"my_model\")\n",
    "np.testing.assert_allclose(loaded_1(input_arr), outputs)\n",
    "np.testing.assert_allclose(loaded_2(input_arr), outputs)\n",
    "\n",
    "print(\"Original model:\", model)\n",
    "print(\"Model Loaded with custom objects:\", loaded_1)\n",
    "print(\"Model loaded without the custom object class:\", loaded_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first loaded model is loaded using the config and CustomModel class. The second model is loaded by dynamically creating the model class that acts like the original model.\n",
    "\n",
    "第一个加载的模型里包含了自定义模型类的设置信息。第二个加载的模型里动态的创建了一个模型类，其表现和原模型类似"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Configuring the SavedModel**\n",
    "\n",
    "New in TensoFlow 2.4 The argument save_traces has been added to model.save, which allows you to toggle SavedModel function tracing. Functions are saved to allow the Keras to re-load custom objects without the original class definitons, so when save_traces=False, all custom objects must have defined get_config/from_config methods. When loading, the custom objects must be passed to the custom_objects argument. save_traces=False reduces the disk space used by the SavedModel and saving time.\n",
    "\n",
    "**SavedModel设置**\n",
    "\n",
    "TensoFlow 2.4的一个新功能是给model.save（）添加了新参数“save_traces”。这个允许你更改SavedModel函数对保存对象的检查方式。 模型被保存是为了让Keras在缺少原始类定义的条件下重新加载自定义对象。所以，如果“save_traces=False”，那么所有的自定义对象都必须有定义好的“get_config/from_config”方法。在加载模型的时候，这些自定义对象都会被传递给“custom_objects”参数。“save_traces=False”可以减少在通过SavedModel格式保存时的保存空间和耗时"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras H5 format\n",
    "Keras also supports saving a single HDF5 file containing the model's architecture, weights values, and compile() information. It is a light-weight alternative to SavedModel.\n",
    "\n",
    "### Keras H5格式\n",
    "Keras同样支持将模型的结构，权重，汇编信息保存为单独的HDF5文件，它是SavedModel的轻量级替代品。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step - loss: 1.0986\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24af5ebe880>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example\n",
    "\n",
    "model = get_model()\n",
    "\n",
    "# Train the model.\n",
    "#训练模型\n",
    "test_input = np.random.random((128, 32))\n",
    "test_target = np.random.random((128, 1))\n",
    "model.fit(test_input, test_target)\n",
    "\n",
    "# Calling `save('my_model.h5')` creates a h5 file `my_model.h5`.\n",
    "# 保存为H5文件\n",
    "model.save(\"my_h5_model.h5\")\n",
    "\n",
    "# It can be used to reconstruct the model identically.\n",
    "# 重建一个相同的模型\n",
    "reconstructed_model = keras.models.load_model(\"my_h5_model.h5\")\n",
    "\n",
    "# Let's check:\n",
    "# 检查\n",
    "np.testing.assert_allclose(\n",
    "    model.predict(test_input), reconstructed_model.predict(test_input)\n",
    ")\n",
    "\n",
    "# The reconstructed model is already compiled and has retained the optimizer\n",
    "# state, so training can resume:\n",
    "# 这个重建的模型已经包含了优化器和状态信息，所以它可以训练可以继续\n",
    "reconstructed_model.fit(test_input, test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limitations**\n",
    "\n",
    "Compared to the SavedModel format, there are two things that don't get included in the H5 file:\n",
    "\n",
    "1. External losses & metrics added via model.add_loss() & model.add_metric() are not saved (unlike SavedModel). If you have such losses & metrics on your model and you want to resume training, you need to add these losses back yourself after loading the model. Note that this does not apply to losses/metrics created inside layers via self.add_loss() & self.add_metric(). As long as the layer gets loaded, these losses & metrics are kept, since they are part of the call method of the layer.\n",
    "2. The computation graph of custom objects such as custom layers is not included in the saved file. At loading time, Keras will need access to the Python classes/functions of these objects in order to reconstruct the model. See Custom objects.\n",
    "\n",
    "**局限**\n",
    "和SavedModel相比，H5有两件事无法做到：\n",
    "1. H5无法保存通过model.add_loss() 和 model.add_metric()传递的损失函数和指标信息。如果你的模型含有这些信息并且你打算在模型回复后继续训练，你必须手动添加这些信息。 注意，由模型内部层创建的损失函数和指标信息是可以保存下来的。这是因为这些信息是call方法的一部分，一旦层被加载，这些信息也就保存了下来\n",
    "2. 自定义对象结构如自定义层是不包含在保存文件里的。当加载模型时，Keras会访问这些对象的pyhton类或者函数来重建模型。请参阅“自定义对象”一节"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the architecture\n",
    "\n",
    "The model's configuration (or architecture) specifies what layers the model contains, and how these layers are connected*. If you have the configuration of a model, then the model can be created with a freshly initialized state for the weights and no compilation information.\n",
    "\n",
    "*Note this only applies to models defined using the functional or Sequential apis not subclassed models.\n",
    "\n",
    "## 保存结构\n",
    "\n",
    "模型的设置（或者说结构）决定了模型含有哪些层，以及这些层是如何相互连接的。如果你有模型的设置信息，哪些这个模型就可以在初始化权重状态下创建模型（即丢失训练信息）而不需要汇编信息\n",
    "\n",
    "**注意**这只对顺序模型和函数式模型有效，对子类模型无效"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration of a Sequential model or Functional API model\n",
    "### 顺序模型或函数式API模型的设置\n",
    "\n",
    "These types of models are explicit graphs of layers: their configuration is always available in a structured form.\n",
    "\n",
    "这两类模型有着明确的层结构： 他们的设置永远是结构化的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**APIs**\n",
    "1. get_config() and from_config()\n",
    "2. tf.keras.models.model_to_json() and tf.keras.models.model_from_json()\n",
    "\n",
    "**get_config() and from_config()**\n",
    "\n",
    "Calling config = model.get_config() will return a Python dict containing the configuration of the model. The same model can then be reconstructed via Sequential.from_config(config) (for a Sequential model) or Model.from_config(config) (for a Functional API model).\n",
    "\n",
    "The same workflow also works for any serializable layer.\n",
    "\n",
    "**APIs**\n",
    "1. get_config()和from_config()\n",
    "2. tf.keras.models.model_to_json() 和 tf.keras.models.model_from_json()\n",
    "\n",
    "**et_config()和from_config()**\n",
    "\n",
    "设置为config = model.get_config()时，会返回包含模型设置信息的python字典；模型可以通过“Sequential.from_config(config)”（顺序模型适用）或者“Model.from_config(config)”（函数式API适用）\n",
    "\n",
    "这个流程对任意次序化层也同样适用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "#Layer example:\n",
    "###############\n",
    "\n",
    "layer = keras.layers.Dense(3, activation=\"relu\")\n",
    "layer_config = layer.get_config()\n",
    "new_layer = keras.layers.Dense.from_config(layer_config)\n",
    "\n",
    "\n",
    "\n",
    "##########################\n",
    "#Sequential model example:\n",
    "##########################\n",
    "\n",
    "model = keras.Sequential([keras.Input((32,)), keras.layers.Dense(1)])\n",
    "config = model.get_config()\n",
    "new_model = keras.Sequential.from_config(config)\n",
    "\n",
    "\n",
    "\n",
    "##########################\n",
    "#Functional model example:\n",
    "##########################\n",
    "\n",
    "inputs = keras.Input((32,))\n",
    "outputs = keras.layers.Dense(1)(inputs)\n",
    "model = keras.Model(inputs, outputs)\n",
    "config = model.get_config()\n",
    "new_model = keras.Model.from_config(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "For build-in layers, sequential model, and functional model, these objects can get configuration information by get_config() and recreated it by from_config(). Like this:\n",
    "1. config_inforamtion = layers.get_config()/Suqential_Model.get_config()/Functional_Model.get_config()\n",
    "2. new_layer_or Model = keras.layers.Dense.from_config(config_inforamtion)/eras.Sequential.from_config(config_inforamtion)/ keras.Model.from_config(config_inforamtion)\n",
    "\n",
    "对于内置的层，顺序模型和函数式API，可以通过get_config()和from_config()实现提取设置信息并重建模型或层。就像这样\n",
    "1. 模型信息 = layers.get_config()/Suqential_Model.get_config()/Functional_Model.get_config()\n",
    "2. 新的模型或层 =  keras.layers.Dense.from_config(config_inforamtion)/eras.Sequential.from_config(config_inforamtion)/ keras.Model.from_config(config_inforamtion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**to_json() and tf.keras.models.model_from_json()**\n",
    "\n",
    "This is similar to get_config / from_config, except it turns the model into a JSON string, which can then be loaded without the original model class. It is also specific to models, it isn't meant for layers.\n",
    "\n",
    "**to_json()和tf.keras.models.model_from_json()方法**\n",
    "\n",
    "这两个方法和get_config / from_config类似，区别在于他们会将模型信息转化为JSON格式，这样及时没有源模型类也能加载模型。不过这只适用于模型，不适用于层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "\n",
    "model = keras.Sequential([keras.Input((32,)), keras.layers.Dense(1)])\n",
    "json_config = model.to_json()\n",
    "new_model = keras.models.model_from_json(json_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom objects\n",
    "***Models and layers***\n",
    "\n",
    "The architecture of subclassed models and layers are defined in the methods \\__init__ and call. They are considered Python bytecode, which cannot be serialized into a JSON-compatible config -- you could try serializing the bytecode (e.g. via pickle), but it's completely unsafe and means your model cannot be loaded on a different system.\n",
    "\n",
    "In order to save/load a model with custom-defined layers, or a subclassed model, you should overwrite the get_config and optionally from_config methods. Additionally, you should use register the custom object so that Keras is aware of it.\n",
    "\n",
    "### 自定义对象\n",
    "\n",
    "**层与模型**\n",
    "\n",
    "子类模型和层的结构是通过__init__和 call定义的。这些对象会被识别为python字节码，所以无法被序列化并保存为JSON兼容配置。你可以尝试去序列化这些字节码（比如通过pickle），但是这不安全，同时也意味着你的模型无法在其他系统下加载\n",
    "\n",
    "为了保存含有自定义层的模型或者自定义模型， 你可以重写getget_config和optionally from_config（有需要的话）两个方法，并用新方法覆盖旧的。此外，你可以注册这些自定义对象，这样Keras就能识别它们了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Custom functions**\n",
    "\n",
    "Custom-defined functions (e.g. activation loss or initialization) do not need a get_config method. The function name is sufficient for loading as long as it is registered as a custom object.\n",
    "\n",
    "**自定义函数**\n",
    "\n",
    "自定义函数（如激活函数和初始化函数）并不需要get_config。只要这些函数已经注册，那么函数名已经足够用于恢复"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading the TensorFlow graph only**\n",
    "\n",
    "It's possible to load the TensorFlow graph generated by the Keras. If you do so, you won't need to provide any custom_objects. You can do so like this:\n",
    "\n",
    "**只加载TensorFlow层次结构**\n",
    "\n",
    "通过Keras只加载TensorFlow层次结构是可行的。如果你这么做，你不需要提供任何自定义对象。 你可以像这样实现这一功能："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"my_model\")\n",
    "tensorflow_graph = tf.saved_model.load(\"my_model\")\n",
    "x = np.random.uniform(size=(4, 32)).astype(np.float32)\n",
    "predicted = tensorflow_graph(x).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note 学习笔记\n",
    "when we load the whole model from \"my model\", we use 'keras.models.load_model()' function; Here, we just load the graph and we use \"tf.saved_model.load()\". So, loading model or part of model depends on which function we choose.\n",
    "\n",
    "当我们加载整个模型时，我们使用的是'keras.models.load_model()'函数；而在这里我们只加载层次结构，我们使用的是\"tf.saved_model.load()\"。所以加载全部模型或部分模型成分取决于我们所使用的函数\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this method has several drawbacks:\n",
    "\n",
    "1. For traceability reasons, you should always have access to the custom objects that were used. You wouldn't want to put in production a model that you cannot re-create.\n",
    "2. The object returned by tf.saved_model.load isn't a Keras model. So it's not as easy to use. For example, you won't have access to .predict() or .fit()\n",
    "\n",
    "注意这一方法有以下缺点：\n",
    "1. 从可追踪性的角度出发，你应该可以访问任何被使用的自定义对象。你也不会想要创建一个无法再次被创建的模型\n",
    "2. tf.saved_model.load（）所返回的对象并不是一个Keras模型，所以这并不好用。比如说，你无法在这个模型上调用.predict()或者.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if its use is discouraged, it can help you if you're in a tight spot, for example, if you lost the code of your custom objects or have issues loading the model with tf.keras.models.load_model().\n",
    "\n",
    "You can find out more in the [page about](https://www.tensorflow.org/api_docs/python/tf/saved_model/load) tf.saved_model.load\n",
    "\n",
    "虽然不鼓励使用这种方法，不过它还是可以帮你应急的。比如你丢失了你自定义对象的代码，或者当你在使用tf.keras.models.load_model()加载模型时遇到的问题\n",
    "\n",
    "你可以在[这里](https://www.tensorflow.org/api_docs/python/tf/saved_model/load)找到更多关于tf.saved_model.load的信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining the config methods**\n",
    "\n",
    "Specifications:\n",
    "\n",
    "1. get_config should return a JSON-serializable dictionary in order to be compatible with the Keras architecture- and model-saving APIs.\n",
    "2. from_config(config) (classmethod) should return a new layer or model object that is created from the config. The default implementation returns cls(**config).\n",
    "\n",
    "**定义config方法**\n",
    "\n",
    "具体来说\n",
    "1. get_config会返回一个JSON次序化的字典来兼容Keras结构和模型保存API\n",
    "2. from_config(config)（类方法）则会返回一个新的，从config中创建的层或者模型对象。默认实现会返回cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exmaple\n",
    "\n",
    "class CustomLayer(keras.layers.Layer):\n",
    "    def __init__(self, a):\n",
    "        self.var = tf.Variable(a, name=\"var_a\")\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        if training:\n",
    "            return inputs * self.var\n",
    "        else:\n",
    "            return inputs\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"a\": self.var.numpy()}\n",
    "\n",
    "    # There's actually no need to define `from_config` here, since returning\n",
    "    # `cls(**config)` is the default behavior.\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "\n",
    "layer = CustomLayer(5)\n",
    "layer.var.assign(2)\n",
    "\n",
    "serialized_layer = keras.layers.serialize(layer)\n",
    "new_layer = keras.layers.deserialize(\n",
    "    serialized_layer, custom_objects={\"CustomLayer\": CustomLayer}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Registering the custom object**\n",
    "\n",
    "Keras keeps a note of which class generated the config. From the example above, tf.keras.layers.serialize generates a serialized form of the custom layer:\n",
    "\n",
    "**注册自定义对象**\n",
    "\n",
    "Keras有一个“记事本”，这个记事本记录了哪些类可以生成配置信息。在上面的示例中，tf.keras.layers.serialize就生成了一个自定义对象的序列化格式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'class_name': 'CustomLayer', 'config': {'a': 2} }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras keeps a master list of all built-in layer, model, optimizer, and metric classes, which is used to find the correct class to call from_config. If the class can't be found, then an error is raised (Value Error: Unknown layer). There are a few ways to register custom classes to this list:\n",
    "\n",
    "1. Setting custom_objects argument in the loading function. (see the example in section above \"Defining the config methods\")\n",
    "2. tf.keras.utils.custom_object_scope or tf.keras.utils.CustomObjectScope\n",
    "3. tf.keras.utils.register_keras_serializable\n",
    "\n",
    "Keras保存了所有内置层，模型，优化器和指标类的主要列表。这个列表可以用来为from_config查找正确的类。如果没有找到对应的类，则会返回一个错误信息。这里有几个将自定义模型注册登记在这个列表里的办法：\n",
    "1. 在加载函数的时候设置自定义对象的参数（参见**定义config方法**一节的示例）\n",
    "2. tf.keras.utils.custom_object_scope或者tf.keras.utils.CustomObjectScope\n",
    "3. tf.keras.utils.register_keras_serializable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Custom layer and function example**\n",
    "\n",
    "**自定义层和模型示例**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "\n",
    "class CustomLayer(keras.layers.Layer):\n",
    "    def __init__(self, units=32, **kwargs):\n",
    "        super(CustomLayer, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(\n",
    "            shape=(input_shape[-1], self.units),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape=(self.units,), initializer=\"random_normal\", trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(CustomLayer, self).get_config()\n",
    "        config.update({\"units\": self.units})\n",
    "        return config\n",
    "\n",
    "\n",
    "def custom_activation(x):\n",
    "    return tf.nn.tanh(x) ** 2\n",
    "\n",
    "\n",
    "# Make a model with the CustomLayer and custom_activation\n",
    "# 用自定义层和自定义激活函数来构建一个模型\n",
    "inputs = keras.Input((32,))\n",
    "x = CustomLayer(32)(inputs)\n",
    "outputs = keras.layers.Activation(custom_activation)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "# Retrieve the config\n",
    "# 读取配置信息\n",
    "config = model.get_config()\n",
    "\n",
    "# At loading time, register the custom objects with a `custom_object_scope`:\n",
    "# 在读取的时候，将自定义对象注册为一个“custom_object_scope”\n",
    "custom_objects = {\"CustomLayer\": CustomLayer, \"custom_activation\": custom_activation} # 生成自定义对象列表\n",
    "with keras.utils.custom_object_scope(custom_objects): # 通过keras.utils.custom_object_scope进行注册\n",
    "    new_model = keras.Model.from_config(config) # 根据配置信息（config）重建模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note 学习笔记\n",
    "\n",
    "In my opinion, building model looks like building house with two type of materials (build-in objects and custom objects).\n",
    "\n",
    "when we recreate a model based on config inforamtion, it means we ask Keras re-build a house based on our material list. However,the keras only search material in the build-in object list. So, if our model is built with costum objects, the keras cannot find it to rebuild. Therefore, we can add the custom objects into the build-in list, or warp the custom object with a build-in objects to help Keras rebuild a now house successfully.\n",
    "\n",
    "在我看来，建模就好像用两种材料（内置对象，自定义对象）建房子\n",
    "\n",
    "当我根据配置信息重建模型时，就相当于我要求Keras根据我提供的材料清单来重建一栋房子。然后，Keras只会从内置对象列表中搜索所需要的材料。所以，如果我的模型中含有自定义对象，Keras就无法找到我所要求的材料来重建房子。 因此，我们可以通过将自定义对象加入内置对象列表（方式一）或者用内置对象来包装自定义对象的方式（方式二）来帮助Keras成功的重建房子。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-memory model cloning\n",
    "### 内存模型克隆\n",
    "\n",
    "You can also do in-memory cloning of a model via tf.keras.models.clone_model(). This is equivalent to getting the config then recreating the model from its config (so it does not preserve compilation information or layer weights values).\n",
    "\n",
    "你可以通过tf.keras.models.clone_model()实现在内存中克隆一个模型。这相当于得到配置信息并马上基于此信息重建模型（所以不含任何汇编信息或者层的权重信息）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "with keras.utils.custom_object_scope(custom_objects):\n",
    "    new_model = keras.models.clone_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving & loading only the model's weights values\n",
    "You can choose to only save & load a model's weights. This can be useful if:\n",
    "\n",
    "1. You only need the model for inference: in this case you won't need to restart training, so you don't need the compilation information or optimizer state.\n",
    "2. You are doing transfer learning: in this case you will be training a new model reusing the state of a prior model, so you don't need the compilation information of the prior model.\n",
    "\n",
    "## 仅保存或加载模型的权重信息\n",
    "\n",
    "你可以选择仅保存或在家模型的权重信息，这在以下情况下非常有用：\n",
    "1. 你只需要模型用于预测：这种情况下，你不需要重新训练模型，所以你也不需要汇编信息和优化器状态\n",
    "2. 你在做迁移学习：这种情况下，你只需要前一个模型的状态信息用于训练下一个新模型，所以你不需要前一个模型的汇编信息\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APIs for in-memory weight transfer\n",
    "### 用于内存权重迁移的APIs\n",
    "\n",
    "Weights can be copied between different objects by using get_weights and set_weights:\n",
    "\n",
    "1. tf.keras.layers.Layer.get_weights(): Returns a list of numpy arrays.\n",
    "2. tf.keras.layers.Layer.set_weights(): Sets the model weights to the values in the weights argument.\n",
    "\n",
    "using get_weights和set_weights可以复制不同对象间的权重信息\n",
    "1. tf.keras.layers.Layer.get_weights(): 返回Numpy数组列表\n",
    "2. tf.keras.layers.Layer.set_weights(): 将模型权重设置为权重参数的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "# Example: Transfering weights from one layer to another, in memory\n",
    "###################################################################\n",
    "def create_layer():\n",
    "    layer = keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\")\n",
    "    layer.build((None, 784))\n",
    "    return layer\n",
    "\n",
    "\n",
    "layer_1 = create_layer()\n",
    "layer_2 = create_layer()\n",
    "\n",
    "# Copy weights from layer 1 to layer 2\n",
    "layer_2.set_weights(layer_1.get_weights())\n",
    "\n",
    "\n",
    "\n",
    "########################################################################################################\n",
    "# Example: Transfering weights from one model to another model with a compatible architecture, in memory\n",
    "########################################################################################################\n",
    "# Create a simple functional model\n",
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = keras.layers.Dense(10, name=\"predictions\")(x)\n",
    "functional_model = keras.Model(inputs=inputs, outputs=outputs, name=\"3_layer_mlp\")\n",
    "\n",
    "# Define a subclassed model with the same architecture\n",
    "class SubclassedModel(keras.Model):\n",
    "    def __init__(self, output_dim, name=None):\n",
    "        super(SubclassedModel, self).__init__(name=name)\n",
    "        self.output_dim = output_dim\n",
    "        self.dense_1 = keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\")\n",
    "        self.dense_2 = keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\")\n",
    "        self.dense_3 = keras.layers.Dense(output_dim, name=\"predictions\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense_1(inputs)\n",
    "        x = self.dense_2(x)\n",
    "        x = self.dense_3(x)\n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"output_dim\": self.output_dim, \"name\": self.name}\n",
    "\n",
    "\n",
    "subclassed_model = SubclassedModel(10)\n",
    "# Call the subclassed model once to create the weights.\n",
    "subclassed_model(tf.ones((1, 784)))\n",
    "\n",
    "# Copy weights from functional_model to subclassed_model.\n",
    "subclassed_model.set_weights(functional_model.get_weights())\n",
    "\n",
    "assert len(functional_model.weights) == len(subclassed_model.weights) # 如果两者的权重数量不同，报错\n",
    "for a, b in zip(functional_model.weights, subclassed_model.weights): # 如果两者的权重数值不同，报错\n",
    "    np.testing.assert_allclose(a.numpy(), b.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The case of stateless layers**\n",
    "\n",
    "Because stateless layers do not change the order or number of weights, models can have compatible architectures even if there are extra/missing stateless layers.\n",
    "\n",
    "**无状态层的情况**\n",
    "\n",
    "因为无状态层不会改变权重的顺序和数值，模型可以具有兼容结构，无论其有没有无状态层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = keras.layers.Dense(10, name=\"predictions\")(x)\n",
    "functional_model = keras.Model(inputs=inputs, outputs=outputs, name=\"3_layer_mlp\")\n",
    "\n",
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "\n",
    "# Add a dropout layer, which does not contain any weights.\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "outputs = keras.layers.Dense(10, name=\"predictions\")(x)\n",
    "functional_model_with_dropout = keras.Model(\n",
    "    inputs=inputs, outputs=outputs, name=\"3_layer_mlp\"\n",
    ")\n",
    "\n",
    "functional_model_with_dropout.set_weights(functional_model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APIs for saving weights to disk & loading them back\n",
    "### 用于将权重保存到本地和从本次加载权重的APIs\n",
    "\n",
    "Weights can be saved to disk by calling model.save_weights in the following formats:\n",
    "\n",
    "1. TensorFlow Checkpoint\n",
    "2. HDF5\n",
    "\n",
    "The default format for model.save_weights is TensorFlow checkpoint. There are two ways to specify the save format:\n",
    "\n",
    "1. save_format argument: Set the value to save_format=\"tf\" or save_format=\"h5\".\n",
    "2. path argument: If the path ends with .h5 or .hdf5, then the HDF5 format is used. Other suffixes will result in a TensorFlow checkpoint unless save_format is set.\n",
    "\n",
    "权重可以通过调用model.save_weights来保存到本地，保存的格式有：\n",
    "1. TensorFlow 检查点\n",
    "2. HDF5\n",
    "\n",
    "model.save_weights的默认保存格式是TensorFlow 检查点。有两种方式可以指定特定的保存格式：\n",
    "1. 通过save_format参数指定：设定参数的值为save_format=\"tf\"或者save_format=\"h5\"\n",
    "2. 通过路径参数指定：如果路径后缀为.h5 或者.hdf5，则保存为HDF5格式，其他路径则保存为TensorFlow 检查点格式，除非同时还设置了save_format参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "\n",
    "like saving and laoding model, there are two ways  to save and load weights:\n",
    "1. TensorFlow formart\n",
    "2. H5 formart\n",
    "\n",
    "Also, we can set the preferred saving format by two ways:\n",
    "1. set argument directly\n",
    "2. set path argument\n",
    "\n",
    "和模型的保存与加载相同，有两种方式可以保存和加载权重：\n",
    "1. TensorFlow格式\n",
    "2. H5格式\n",
    "\n",
    "同样的，我们有两种方式来设置偏好的保存格式：\n",
    "1. 直接设置对应的参数\n",
    "2. 设置保存路径参数\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also an option of retrieving weights as in-memory numpy arrays. Each API has its pros and cons which are detailed below.\n",
    "同样可以选择将权重读取为Numpy数组，可选择的API以及优缺点如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TF Checkpoint format**\n",
    "**TF 检查点格式**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x24af29605e0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example\n",
    "\n",
    "# Runnable example\n",
    "sequential_model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(784,), name=\"digits\"),\n",
    "        keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\"),\n",
    "        keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\"),\n",
    "        keras.layers.Dense(10, name=\"predictions\"),\n",
    "    ]\n",
    ")\n",
    "sequential_model.save_weights(\"ckpt\")\n",
    "load_status = sequential_model.load_weights(\"ckpt\")\n",
    "\n",
    "# `assert_consumed` can be used as validation that all variable values have been\n",
    "# restored from the checkpoint. See `tf.train.Checkpoint.restore` for other\n",
    "# methods in the Status object.\n",
    "load_status.assert_consumed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Format details**\n",
    "\n",
    "The TensorFlow Checkpoint format saves and restores the weights using object attribute names. For instance, consider the tf.keras.layers.Dense layer. The layer contains two weights: dense.kernel and dense.bias. When the layer is saved to the tf format, the resulting checkpoint contains the keys \"kernel\" and \"bias\" and their corresponding weight values. For more information see [\"Loading mechanics\" in the TF Checkpoint guide.](https://www.tensorflow.org/guide/checkpoint#loading_mechanics)\n",
    "\n",
    "Note that attribute/graph edge is named after the name used in parent object, not the name of the variable. Consider the CustomLayer in the example below. The variable CustomLayer.var is saved with \"var\" as part of key, not \"var_a\".\n",
    "\n",
    "**格式细节**\n",
    "TensorFlow检查点格式会根据属性名称对权重进行保存会恢复。例如，有一个tf.keras.layers.Dense层（稠密层）。这个层有两个权重：dense.kernel和dense.bias. 当这个层以检查点格式保存权重时，所产生的检查点会包含“kernel”和\"bias\"两个名称以及对应的权重。更多信息请参见[这里](https://www.tensorflow.org/guide/checkpoint#loading_mechanics)\n",
    "\n",
    "注意，数据/层级是根据其父对象的名字命名的，而不是这个变量本身。请参考以下示例。变量CustomLayer.var用“var”作为键的一部分保存，而不是“var_a”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_CHECKPOINTABLE_OBJECT_GRAPH': tf.string,\n",
       " 'layer/var/.ATTRIBUTES/VARIABLE_VALUE': tf.int32,\n",
       " 'save_counter/.ATTRIBUTES/VARIABLE_VALUE': tf.int64}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomLayer(keras.layers.Layer):\n",
    "    def __init__(self, a):\n",
    "        self.var = tf.Variable(a, name=\"var_a\")\n",
    "\n",
    "\n",
    "layer = CustomLayer(5)\n",
    "layer_ckpt = tf.train.Checkpoint(layer=layer).save(\"custom_layer\")\n",
    "\n",
    "ckpt_reader = tf.train.load_checkpoint(layer_ckpt)\n",
    "\n",
    "ckpt_reader.get_variable_to_dtype_map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note 学习笔记\n",
    "The official explanation is so comfused. My idea is that although we give the CustomLayer.var a name by tf.Variable(a, name=\"var_a\"), but this action will not impact the expression of its key. No matter what name the function given, the key always set \"var\" as a part of key. If you want to change it, you should change the \"self.var\" part.\n",
    "\n",
    "you can try \"self.var_test\" or \"self.this_is_not_a_variable\" in the above example and see how the key change.\n",
    "\n",
    "官方的解释有点难懂。我的理解是，尽管我们通过 tf.Variable(a, name=\"var_a\")对这个CustomLayer.var进行了命名，但是这个行为不会改变保存时候的键值。不论我们怎么通过 tf.Variable(a, name=\"var_a\")传递名称，这个键值永远会用“var”来作为其一部分。 如果要变量这部分键值，你应该修改\"self.var\"部分。\n",
    "\n",
    "你可以在上面的例子中试试\"self.var_test\"或者\"self.this_is_not_a_variable\"，然后看看键值会如何改变"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transfer learning example**\n",
    "\n",
    "Essentially, as long as two models have the same architecture, they are able to share the same checkpoint.\n",
    "\n",
    "**迁移学习示例**\n",
    "\n",
    "基本上，如果两个模型有着一样的结构，那么他们就可以共享同一个检查点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"pretrained_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "digits (InputLayer)          [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "=================================================================\n",
      "Total params: 54,400\n",
      "Trainable params: 54,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      " --------------------------------------------------\n",
      "Model: \"new_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "digits (InputLayer)          [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 54,725\n",
      "Trainable params: 54,725\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "pretrained (Functional)      (None, 64)                54400     \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 54,725\n",
      "Trainable params: 54,725\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x24af6002f10>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example\n",
    "\n",
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = keras.layers.Dense(10, name=\"predictions\")(x)\n",
    "functional_model = keras.Model(inputs=inputs, outputs=outputs, name=\"3_layer_mlp\")\n",
    "\n",
    "# Extract a portion of the functional model defined in the Setup section.\n",
    "# 抽取一部分在环境设定部分定义的函数式模型\n",
    "\n",
    "# The following lines produce a new model that excludes the final output\n",
    "# layer of the functional model.\n",
    "# 接来下的模型生成了一个包含函数式模型输出层的新模型\n",
    "pretrained = keras.Model(\n",
    "    functional_model.inputs, functional_model.layers[-1].input, name=\"pretrained_model\"\n",
    ")\n",
    "# Randomly assign \"trained\" weights.\n",
    "# 随机的分配“训练”权重\n",
    "for w in pretrained.weights:\n",
    "    w.assign(tf.random.normal(w.shape))\n",
    "pretrained.save_weights(\"pretrained_ckpt\")\n",
    "pretrained.summary()\n",
    "\n",
    "# Assume this is a separate program where only 'pretrained_ckpt' exists.\n",
    "# Create a new functional model with a different output dimension.\n",
    "# 假设这是一个单独的程序，只有'pretrained_ckpt'存在（只能通过'pretrained_ckpt'获得权重）\n",
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = keras.layers.Dense(5, name=\"predictions\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"new_model\")\n",
    "\n",
    "# Load the weights from pretrained_ckpt into model.\n",
    "# 从pretrained_ckpt加载权重到模型中\n",
    "model.load_weights(\"pretrained_ckpt\")\n",
    "\n",
    "# Check that all of the pretrained weights have been loaded.\n",
    "# 检查所有被加载的的权重\n",
    "for a, b in zip(pretrained.weights, model.weights):\n",
    "    np.testing.assert_allclose(a.numpy(), b.numpy())\n",
    "\n",
    "print(\"\\n\", \"-\" * 50)\n",
    "model.summary()\n",
    "\n",
    "# Example 2: Sequential model\n",
    "# Recreate the pretrained model, and load the saved weights.\n",
    "# 重建一个未经训练的模型，并加入保存的权重信息\n",
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "pretrained_model = keras.Model(inputs=inputs, outputs=x, name=\"pretrained\")\n",
    "\n",
    "# Sequential example:\n",
    "# 顺序模型示例\n",
    "model = keras.Sequential([pretrained_model, keras.layers.Dense(5, name=\"predictions\")])\n",
    "model.summary()\n",
    "\n",
    "pretrained_model.load_weights(\"pretrained_ckpt\")\n",
    "\n",
    "# Warning! Calling `model.load_weights('pretrained_ckpt')` won't throw an error,\n",
    "# but will *not* work as expected. If you inspect the weights, you'll see that\n",
    "# none of the weights will have loaded. `pretrained_model.load_weights()` is the\n",
    "# correct method to call.\n",
    "\n",
    "# 注意：调用model.load_weights('pretrained_ckpt')不会导致错误，但是它也不会如你预期那样工作：没有权重被载入。\n",
    "# `pretrained_model.load_weights()`才是正确的调用方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is generally recommended to stick to the same API for building models. If you switch between Sequential and Functional, or Functional and subclassed, etc., then always rebuild the pre-trained model and load the pre-trained weights to that model.\n",
    "\n",
    "The next question is, how can weights be saved and loaded to different models if the model architectures are quite different? The solution is to use tf.train.Checkpoint to save and restore the exact layers/variables.\n",
    "\n",
    "通常建议用相同的API来构建模型。如果你在顺序API和函数式APS之间或者函数式API和子类之间切换使用，则会重建一个未经训练的模型，并且载入未经训练的权重到这个模型中\n",
    "\n",
    "另一个问题是，如果模型的结构差异较大，那么权重如何保存并加载到不同的模型之中呢。解决方案是使用tf.train.Checkpoint来保存和加载额外的层和变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:2281: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x24af0f8bbb0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example\n",
    "\n",
    "# Create a subclassed model that essentially uses functional_model's first\n",
    "# and last layers.\n",
    "# First, save the weights of functional_model's first and last dense layers.\n",
    "first_dense = functional_model.layers[1]\n",
    "last_dense = functional_model.layers[-1]\n",
    "ckpt_path = tf.train.Checkpoint(\n",
    "    dense=first_dense, kernel=last_dense.kernel, bias=last_dense.bias\n",
    ").save(\"ckpt\")\n",
    "\n",
    "# Define the subclassed model.\n",
    "class ContrivedModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(ContrivedModel, self).__init__()\n",
    "        self.first_dense = keras.layers.Dense(64)\n",
    "        self.kernel = self.add_variable(\"kernel\", shape=(64, 10))\n",
    "        self.bias = self.add_variable(\"bias\", shape=(10,))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.first_dense(inputs)\n",
    "        return tf.matmul(x, self.kernel) + self.bias\n",
    "\n",
    "\n",
    "model = ContrivedModel()\n",
    "# Call model on inputs to create the variables of the dense layer.\n",
    "_ = model(tf.ones((1, 784)))\n",
    "\n",
    "# Create a Checkpoint with the same structure as before, and load the weights.\n",
    "tf.train.Checkpoint(\n",
    "    dense=model.first_dense, kernel=model.kernel, bias=model.bias\n",
    ").restore(ckpt_path).assert_consumed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5 format\n",
    "\n",
    "The HDF5 format contains weights grouped by layer names. The weights are lists ordered by concatenating the list of trainable weights to the list of non-trainable weights (same as layer.weights). Thus, a model can use a hdf5 checkpoint if it has the same layers and trainable statuses as saved in the checkpoint.\n",
    "\n",
    "### HDF5 格式\n",
    "\n",
    "HDF5 格式将权重按层名称打包。这些权重按照从可训练权重到不可训练权重的次序列出（层权重也是如此）。因此模型可以使用HDF5格式检查点，如果这个模型和检查点有着相同的层和“可训练”状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runnable example\n",
    "sequential_model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(784,), name=\"digits\"),\n",
    "        keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\"),\n",
    "        keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\"),\n",
    "        keras.layers.Dense(10, name=\"predictions\"),\n",
    "    ]\n",
    ")\n",
    "sequential_model.save_weights(\"weights.h5\")\n",
    "sequential_model.load_weights(\"weights.h5\")\n",
    "\n",
    "## 这个模型的所有层都是稠密层，并且没有不可训练的权重，所以可以通过HDF5格式保存和恢复权重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that changing layer.trainable may result in a different layer.weights ordering when the model contains nested layers.\n",
    "\n",
    "注意，当模型包含层嵌套结构时，改变层的可训练状态会导致一个不同的层权重排序。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables: ['nested/dense_1/kernel:0', 'nested/dense_1/bias:0', 'nested/dense_2/kernel:0', 'nested/dense_2/bias:0']\n",
      "\n",
      "Changing trainable status of one of the nested layers...\n",
      "\n",
      "variables: ['nested/dense_2/kernel:0', 'nested/dense_2/bias:0', 'nested/dense_1/kernel:0', 'nested/dense_1/bias:0']\n",
      "variable ordering changed: True\n"
     ]
    }
   ],
   "source": [
    "class NestedDenseLayer(keras.layers.Layer):\n",
    "    def __init__(self, units, name=None):\n",
    "        super(NestedDenseLayer, self).__init__(name=name)\n",
    "        self.dense_1 = keras.layers.Dense(units, name=\"dense_1\")\n",
    "        self.dense_2 = keras.layers.Dense(units, name=\"dense_2\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.dense_2(self.dense_1(inputs))\n",
    "\n",
    "# 原始状态的嵌套模型，两个层都是可训练的。先报告layer1的权重，再报告layer2的权重\n",
    "nested_model = keras.Sequential([keras.Input((784,)), NestedDenseLayer(10, \"nested\")])\n",
    "variable_names = [v.name for v in nested_model.weights]\n",
    "print(\"variables: {}\".format(variable_names))\n",
    "\n",
    "# 改变layer1的权重状态为不可训练\n",
    "print(\"\\nChanging trainable status of one of the nested layers...\")\n",
    "nested_model.get_layer(\"nested\").dense_1.trainable = False\n",
    "\n",
    "# 再次查看权重，权重按可训练-不可训练排序，所以layer2在前，layer1在后\n",
    "variable_names_2 = [v.name for v in nested_model.weights]\n",
    "print(\"\\nvariables: {}\".format(variable_names_2))\n",
    "print(\"variable ordering changed:\", variable_names != variable_names_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transfer learning example**\n",
    "\n",
    "When loading pretrained weights from HDF5, it is recommended to load the weights into the original checkpointed model, and then extract the desired weights/layers into a new model.\n",
    "\n",
    "**迁移学习示例**\n",
    "\n",
    "当从HDF5文件中载入未经训练的权重时，推荐的方式是先把权重载入到一个原检查点模型中，然后再提取需要的权重/层，并加入到新模型里面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 54,725\n",
      "Trainable params: 54,725\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "\n",
    "def create_functional_model():\n",
    "    inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "    x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "    x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "    outputs = keras.layers.Dense(10, name=\"predictions\")(x)\n",
    "    return keras.Model(inputs=inputs, outputs=outputs, name=\"3_layer_mlp\")\n",
    "\n",
    "# 先创建模型，然后保存权重\n",
    "functional_model = create_functional_model()\n",
    "functional_model.save_weights(\"pretrained_weights.h5\")\n",
    "\n",
    "# In a separate program:\n",
    "# 又通过同样的方式创建了一个模型，并加入了之前的权重\n",
    "pretrained_model = create_functional_model()\n",
    "pretrained_model.load_weights(\"pretrained_weights.h5\")\n",
    "\n",
    "# Create a new model by extracting layers from the original model:\n",
    "# 提取之前模型的层（最后一层除外），并创建第三个模型\n",
    "extracted_layers = pretrained_model.layers[:-1]\n",
    "extracted_layers.append(keras.layers.Dense(5, name=\"dense_3\"))\n",
    "model = keras.Sequential(extracted_layers)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
