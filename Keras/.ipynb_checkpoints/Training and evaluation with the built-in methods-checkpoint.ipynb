{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and evaluation with the built-in methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "## 环境设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "## 章节介绍\n",
    "This guide covers training, evaluation, and prediction (inference) models when using built-in APIs for training & validation (such as Model.fit(), Model.evaluate() and Model.predict()).\n",
    "\n",
    "If you are interested in leveraging fit() while specifying your own training step function, see the [Customizing what happens in fit() guide.](https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit/)\n",
    "\n",
    "If you are interested in writing your own training & evaluation loops from scratch, see the guide [\"writing a training loop from scratch\".](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch/)\n",
    "\n",
    "In general, whether you are using built-in loops or writing your own, model training & evaluation works strictly in the same way across every kind of Keras model -- Sequential models, models built with the Functional API, and models written from scratch via model subclassing.\n",
    "\n",
    "This guide doesn't cover distributed training, which is covered in our guide to [multi-GPU & distributed training.](https://keras.io/guides/distributed_training/)\n",
    "\n",
    "本指南涵盖了使用内置API（如Model.fit(), Model.evaluate() 和 Model.predict()）进行训练时的训练、评估和预测模型\n",
    "\n",
    "\n",
    "如果你对在指定训练模型训练步骤函数的同时应用fit（），请参考这篇[指南](https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit/)\n",
    "\n",
    "如果你对从零开始构建自己的训练/评估循环有兴趣，请参阅这篇这篇[指南](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch/)\n",
    "\n",
    "一般而言，无论你是使用内置的指令或者自己构建的指令，对于Keras的各类模型（顺序模型，函数式模型，通过模型子类构建的新模型）而言，其训练和评估过程是严格按照相同的方式进行的\n",
    "\n",
    "这篇指南没有包含分布式训练的内容，这部分内容请查阅这篇[指南](https://keras.io/guides/distributed_training/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API overview: a first end-to-end example\n",
    "## API概述：一个端到端的示例\n",
    "\n",
    "When passing data to the built-in training loops of a model, you should either use NumPy arrays (if your data is small and fits in memory) or tf.data Dataset objects. In the next few paragraphs, we'll use the MNIST dataset as NumPy arrays, in order to demonstrate how to use optimizers, losses, and metrics.\n",
    "\n",
    "Let's consider the following model (here, we build in with the Functional API, but it could be a Sequential model or a subclassed model as well):\n",
    "\n",
    "当你传递数据到一个模型的内置训练循环时，你可以选择使用Numoy数组（如果你的数据比较小且可以在内存中进行训练）或者tf.data数据集对象（来进行传递）。在接下来的部分里，我们将使用Numpy数组格式的MNIST数据集来演示如何设置优化器，损失函数和评估指标\n",
    "\n",
    "让我们来看看接下来的模型（演示用的模型是用函数式API构建的，但1其实它可以用顺序模型或者模型子类来进行构建）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\", name=\"predictions\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what the typical end-to-end workflow looks like, consisting of:\n",
    "1. Training\n",
    "2. Validation on a holdout set generated from the original training data\n",
    "3. Evaluation on the test data\n",
    "\n",
    "一个典型的端到端模型工作流程如下：\n",
    "1. 训练\n",
    "2. 使用原始数据集上生成的验证集机型模型验证\n",
    "3. 使用测试数据对模型进行评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use MNIST data for this example\n",
    "# 使用MNIST数据进行演示\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Preprocess the data (these are NumPy arrays)\n",
    "# 数据处理（数据结类型是Numpy数组）\n",
    "x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
    "x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255\n",
    "\n",
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")\n",
    "\n",
    "# Reserve 10,000 samples for validation\n",
    "x_val = x_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = x_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the training configuration (optimizer, loss, metrics)\n",
    "# 设定训练配置（优化器，损失函数和评估指标）\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(),  # Optimizer 优化器\n",
    "    # Loss function to minimize 损失函数最小化\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    # List of metrics to monitor 采用一系列指标来进行监测\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call fit(), which will train the model by slicing the data into \"batches\" of size batch_size, and repeatedly iterating over the entire dataset for a given number of epochs.\n",
    "我们调用fit（）方法，这会开始训练模型：数据将会根据所设定的批量大量划分为多个数据批量，然后模型会训练整个数据集，只到训练次数达到我们所设定的次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Epoch 1/2\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.5777 - sparse_categorical_accuracy: 0.8384 - val_loss: 0.2166 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 2/2\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.1754 - sparse_categorical_accuracy: 0.9482 - val_loss: 0.1353 - val_sparse_categorical_accuracy: 0.9614\n"
     ]
    }
   ],
   "source": [
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=2,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    # 每一次训练结束后，我们通过返回模型验证信息，来监控验证损失和指标\n",
    "    validation_data=(x_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.3442656397819519, 0.1592882126569748],\n",
       " 'sparse_categorical_accuracy': [0.9027000069618225, 0.9524800181388855],\n",
       " 'val_loss': [0.21663400530815125, 0.1353076845407486],\n",
       " 'val_sparse_categorical_accuracy': [0.9381999969482422, 0.9613999724388123]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The returned history object holds a record of the loss values and metric values during training\n",
    "# 返回history对象，这个对象记录了训练过程中的损失值和指标值\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.1358 - sparse_categorical_accuracy: 0.9603\n",
      "test loss, test acc: [0.13578011095523834, 0.9603000283241272]\n",
      "Generate predictions for 3 samples\n",
      "predictions shape: (3, 10)\n"
     ]
    }
   ],
   "source": [
    "# We evaluate the model on the test data via evaluate()\n",
    "# 我们通过evaluate（）方法，在测试集上对模型进行评估\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(x_test, y_test, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# 输出预测值（最后一层的输出：概率）\n",
    "# on new data using `predict`\n",
    "# 在新的数据上应用predict（）方法\n",
    "print(\"Generate predictions for 3 samples\")\n",
    "predictions = model.predict(x_test[:3])\n",
    "print(\"predictions shape:\", predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's review each piece of this workflow in detail.\n",
    "\n",
    "现在，让我们详细回顾这一工作流程的中每一个部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The compile() method: specifying a loss, metrics, and an optimizer\n",
    "## compile()方法：设定损失函数，指标和优化器 \n",
    "\n",
    "To train a model with fit(), you need to specify a loss function, an optimizer, and optionally, some metrics to monitor.\n",
    "\n",
    "You pass these to the model as arguments to the compile() method:\n",
    "\n",
    "为了用fit（）方法训练模型，你需要先设定好损失函数，优化器，以及一些监控指标（如果有需要的话）\n",
    "\n",
    "你将这些信息作为参数，通过compile（）方法将其传递给模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metrics argument should be a list -- your model can have any number of metrics.\n",
    "\n",
    "If your model has multiple outputs, you can specify different losses and metrics for each output, and you can modulate the contribution of each output to the total loss of the model. You will find more details about this in the **Passing data to multi-input, multi-output models** section.\n",
    "\n",
    "指标参数可以是一个列表，这意味着你的模型可以有多个评估指标\n",
    "\n",
    "如果你的模型有多种输出，你可以为每一类输出设定不同的损失函数和指标，还可以控制每一类数据对模型整体损失的贡献。你可以在**传递数据给多输入/输出模型**一节了解到更多关于这一内容的细节"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if you're satisfied with the default settings, in many cases the optimizer, loss, and metrics can be specified via string identifiers as a shortcut:\n",
    "\n",
    "注意：如果你对默认设置感到满意，在很多情况下，可以用字符串作为一个快捷方式来对优化器、损失函数和指标进行设置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"sparse_categorical_accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For later reuse, let's put our model definition and compile step in functions; we will call them several times across different examples in this guide.\n",
    "\n",
    "为了之后可以复用，我们将模型的定义和汇编过程分别定义成函数。在这篇指南中，我们将在多个不同的示例中调用这些函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uncompiled_model():\n",
    "    inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "    x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "    x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\", name=\"predictions\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_compiled_model():\n",
    "    model = get_uncompiled_model()\n",
    "    model.compile(\n",
    "        optimizer=\"rmsprop\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"sparse_categorical_accuracy\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Many built-in optimizers, losses, and metrics are available\n",
    "### 一些可用的内置优化器，损失函数和指标\n",
    "\n",
    "In general, you won't have to create your own losses, metrics, or optimizers from scratch, because what you need is likely to be already part of the Keras API:\n",
    "\n",
    "Optimizers:\n",
    "1. SGD() (with or without momentum)\n",
    "2. RMSprop()\n",
    "3. Adam()\n",
    "4. etc.\n",
    "\n",
    "Losses:\n",
    "1. MeanSquaredError()\n",
    "2. KLDivergence()\n",
    "3. CosineSimilarity()\n",
    "4. etc.\n",
    "\n",
    "Metrics:\n",
    "1. AUC()\n",
    "2. Precision()\n",
    "3. Recall()\n",
    "4. etc.\n",
    "\n",
    "一般而言，你并不需要从头创建一个损失函数、指标或者优化器，因为你需要的东西很可能已经内置进了KerasAPI\n",
    "\n",
    "优化器：\n",
    "1. SGD() (with or without momentum)\n",
    "2. RMSprop()\n",
    "3. Adam()\n",
    "4. etc.\n",
    "\n",
    "损失函数：\n",
    "1. MeanSquaredError()\n",
    "2. KLDivergence()\n",
    "3. CosineSimilarity()\n",
    "4. etc.\n",
    "\n",
    "指标：\n",
    "1. AUC()\n",
    "2. Precision()\n",
    "3. Recall()\n",
    "4. etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom losses\n",
    "### 自定义损失函数\n",
    "If you need to create a custom loss, Keras provides two ways to do so.\n",
    "\n",
    "The first method involves creating a function that accepts inputs y_true and y_pred. The following example shows a loss function that computes the mean squared error between the real data and the predictions\n",
    "\n",
    "如果你需要创造一个自定义损失函数，Keras提供了两种方法。\n",
    "\n",
    "第一种方式是创造一个函数，将真实值和预测值作为输入。 接下来的例子展示了一个计算均方误差的损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 2ms/step - loss: 0.0278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dce330cb20>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def custom_mean_squared_error(y_true, y_pred):\n",
    "    return tf.math.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "\n",
    "model = get_uncompiled_model()\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss=custom_mean_squared_error)\n",
    "\n",
    "# We need to one-hot encode the labels to use MSE\n",
    "y_train_one_hot = tf.one_hot(y_train, depth=10)\n",
    "model.fit(x_train, y_train_one_hot, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need a loss function that takes in parameters beside y_true and y_pred, you can subclass the tf.keras.losses.Loss class and implement the following two methods:\n",
    "\n",
    "1. __init__(self): accept parameters to pass during the call of your loss function\n",
    "2. call(self, y_true, y_pred): use the targets (y_true) and the model predictions (y_pred) to compute the model's loss\n",
    "\n",
    "\n",
    "Let's say you want to use mean squared error, but with an added term that will de-incentivize prediction values far from 0.5 (we assume that the categorical targets are one-hot encoded and take values between 0 and 1). This creates an incentive for the model not to be too confident, which may help reduce overfitting (we won't know if it works until we try!).\n",
    "\n",
    "如果你需要一个损失函数，其参数不仅是真实值和预测值，那么你可以构建一个tf.keras.losses.Loss的类。这需要调用两个方法来实现：\n",
    "1. __init__(self): 接受参数并在调用损失函数时传递给它\n",
    "2. 调用(self, y_true, y_pred)： 用真实值和模型预测值来计算模型损失\n",
    "\n",
    "我们假设你打算使用均方误差，但是加入一个新的项来惩罚那些远离0.5的值（假设分类变量是独热编码的（0-1）），这会形成一种激励，让模型不那么自信（不容易预测为0或者1，因为远离0.5会带来额外的损失惩罚），这样有助于减少过拟合问题（在实验在这个新想法之前，我们都无法知道它是否有效）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 2ms/step - loss: 0.0489\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dce49a3cd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomMSE(keras.losses.Loss):\n",
    "    def __init__(self, regularization_factor=0.1, name=\"custom_mse\"):\n",
    "        super().__init__(name=name)\n",
    "        self.regularization_factor = regularization_factor\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        mse = tf.math.reduce_mean(tf.square(y_true - y_pred))\n",
    "        reg = tf.math.reduce_mean(tf.square(0.5 - y_pred))\n",
    "        return mse + reg * self.regularization_factor\n",
    "\n",
    "\n",
    "model = get_uncompiled_model()\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss=CustomMSE())\n",
    "\n",
    "y_train_one_hot = tf.one_hot(y_train, depth=10)\n",
    "model.fit(x_train, y_train_one_hot, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom metrics\n",
    "### 自定义指标\n",
    "If you need a metric that isn't part of the API, you can easily create custom metrics by subclassing the tf.keras.metrics.Metric class. You will need to implement 4 methods:\n",
    "\n",
    "1. __init__(self), in which you will create state variables for your metric.\n",
    "2. update_state(self, y_true, y_pred, sample_weight=None), which uses the targets y_true and the model predictions y_pred to update the state variables.\n",
    "3. result(self), which uses the state variables to compute the final results.\n",
    "4. reset_states(self), which reinitializes the state of the metric.\n",
    "\n",
    "State update and results computation are kept separate (in update_state() and result(), respectively) because in some cases, the results computation might be very expensive and would only be done periodically.\n",
    "\n",
    "如果你需要一个没有收录在API中的指标，你可以轻易地通过tf.keras.metrics.Metric类来创建一个自定义指标。你需要通过调用四个方法来实现：\n",
    "1. __init__(self)，在这里你可以为你的指标创建一个静态变量\n",
    "2. update_state(self, y_true, y_pred, sample_weight=None),这将使用真实值和预测值来更新这个静态变量\n",
    "3. result(self), 这个方法将用静态变量来计算最终结果\n",
    "4. reset_states(self)，这个方法将重新初始化这个指标的状态（以备下一次使用）\n",
    "\n",
    "状态更新和结果计算是分离的（两者分别在update_state() 和result()中进行）,因为在一些情况下，结果计算的成本会非常高，并且是周期性的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a simple example showing how to implement a CategoricalTruePositives metric that counts how many samples were correctly classified as belonging to a given class:\n",
    "\n",
    "这里是一个展示实现CategoricalTruePositives指标例子。这个指标会统计有多少样本被正确的分类到了所给予的类别中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalTruePositives(keras.metrics.Metric):\n",
    "    def __init__(self, name=\"categorical_true_positives\", **kwargs):\n",
    "        super(CategoricalTruePositives, self).__init__(name=name, **kwargs)\n",
    "        self.true_positives = self.add_weight(name=\"ctp\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = tf.reshape(tf.argmax(y_pred, axis=1), shape=(-1, 1))\n",
    "        values = tf.cast(y_true, \"int32\") == tf.cast(y_pred, \"int32\")\n",
    "        values = tf.cast(values, \"float32\")\n",
    "        if sample_weight is not None:\n",
    "            sample_weight = tf.cast(sample_weight, \"float32\")\n",
    "            values = tf.multiply(values, sample_weight)\n",
    "        self.true_positives.assign_add(tf.reduce_sum(values))\n",
    "\n",
    "    def result(self):\n",
    "        return self.true_positives\n",
    "\n",
    "    def reset_states(self):\n",
    "        # The state of the metric will be reset at the start of each epoch.\n",
    "        # 在每一次的训练后，指标会被重置为初始状态\n",
    "        self.true_positives.assign(0.0)\n",
    "\n",
    "\n",
    "model = get_uncompiled_model()\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[CategoricalTruePositives()],\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling losses and metrics that don't fit the standard signature\n",
    "### 处理不符合一般规范的损失函数和指标\n",
    "\n",
    "The overwhelming majority of losses and metrics can be computed from y_true and y_pred, where y_pred is an output of your model -- but not all of them. For instance, a regularization loss may only require the activation of a layer (there are no targets in this case), and this activation may not be a model output.\n",
    "\n",
    "In such cases, you can call self.add_loss(loss_value) from inside the call method of a custom layer. Losses added in this way get added to the \"main\" loss during training (the one passed to compile()). Here's a simple example that adds activity regularization (note that activity regularization is built-in in all Keras layers -- this layer is just for the sake of providing a concrete example):\n",
    "\n",
    "绝大部分的损失函数和指标都是基于真实值和预测值的（预测值就是模型的输出），但并不是所有的皆是如此。例如，一个正则化损失可能只需要知道层的激活函数即可（这种情况下，没有预测变量），而且激活函数也不是模型的输出\n",
    "\n",
    "在这类情况下，你可以从自定义层的内部方法中调用self.add_loss(loss_value)方法。以这种方式添加的损失会在训练时（通过传递给compile（））加入“主要”损失之中。这里有李哥加入激活正则化（对层的输出进行正则化）的示例（注意所有的Keras层都内置了激活正则化，这里只是做一个示例）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 2ms/step - loss: 3.6878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dce20a2220>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ActivityRegularizationLayer(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        self.add_loss(tf.reduce_sum(inputs) * 0.1)\n",
    "        return inputs  # Pass-through layer.\n",
    "\n",
    "\n",
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "\n",
    "# Insert activity regularization as a layer\n",
    "# 插入激活正则化\n",
    "x = ActivityRegularizationLayer()(x)\n",
    "\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = layers.Dense(10, name=\"predictions\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")\n",
    "\n",
    "# The displayed loss will be much higher than before\n",
    "# 输出的损失会比之前的大很多\n",
    "# due to the regularization component.\n",
    "# 因为加入了正则项\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 2ms/step - loss: 0.5646 - std_of_activation: 0.9570\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dce34f06a0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can do the same for logging metric values, using add_metric()\n",
    "# 你可以用add_metric()方法对日志指标做相同的事\n",
    "\n",
    "class MetricLoggingLayer(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        # The `aggregation` argument defines\n",
    "        # how to aggregate the per-batch values\n",
    "        # over each epoch:\n",
    "        # in this case we simply average them.\n",
    "        # ‘aggregation’参数定义了如何对每次训练中的每个批次进行聚合，在这里我们只需要简单地计算均值即可\n",
    "        self.add_metric(\n",
    "            keras.backend.std(inputs), name=\"std_of_activation\", aggregation=\"mean\"\n",
    "        )\n",
    "        return inputs  # Pass-through layer.\n",
    "\n",
    "\n",
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "\n",
    "# Insert std logging as a layer.\n",
    "x = MetricLoggingLayer()(x)\n",
    "\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = layers.Dense(10, name=\"predictions\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Functional API, you can also call model.add_loss(loss_tensor), or model.add_metric(metric_tensor, name, aggregation).\n",
    "\n",
    "在函数式API中，你同样可以调用model.add_loss(loss_tensor)或者model.add_metric(metric_tensor, name, aggregation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 2ms/step - loss: 3.2508 - std_of_activation: 0.0018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dce9280dc0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x1 = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x2 = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x1)\n",
    "outputs = layers.Dense(10, name=\"predictions\")(x2)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.add_loss(tf.reduce_sum(x1) * 0.1)\n",
    "\n",
    "model.add_metric(keras.backend.std(x1), name=\"std_of_activation\", aggregation=\"mean\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** that when you pass losses via add_loss(), it becomes possible to call compile() without a loss function, since the model already has a loss to minimize.\n",
    "\n",
    "**注意** 你可以通过 add_loss()来传递损失函数，然后再调用compile（）时不加入损失函数。因为这时模型已经拥有了需要最小化的损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following LogisticEndpoint layer: it takes as inputs targets & logits, and it tracks a crossentropy loss via add_loss(). It also tracks classification accuracy via add_metric().\n",
    "\n",
    "思考接来下展示的 LogisticEndpoint层： 它将targets和logits作为输入，并且通过add_loss()方法计算交换熵损失。 它同样也通过add_metric()来计算分类准确性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticEndpoint(keras.layers.Layer):\n",
    "    def __init__(self, name=None):\n",
    "        super(LogisticEndpoint, self).__init__(name=name)\n",
    "        self.loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "        self.accuracy_fn = keras.metrics.BinaryAccuracy()\n",
    "\n",
    "    def call(self, targets, logits, sample_weights=None):\n",
    "        # Compute the training-time loss value and add it\n",
    "        # to the layer using `self.add_loss()`.\n",
    "        loss = self.loss_fn(targets, logits, sample_weights)\n",
    "        self.add_loss(loss)\n",
    "\n",
    "        # Log accuracy as a metric and add it\n",
    "        # to the layer using `self.add_metric()`.\n",
    "        acc = self.accuracy_fn(targets, logits, sample_weights)\n",
    "        self.add_metric(acc, name=\"accuracy\")\n",
    "\n",
    "        # Return the inference-time prediction tensor (for `.predict()`).\n",
    "        return tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use it in a model with two inputs (input data & targets), compiled without a loss argument, like this:\n",
    "你可以在接受两个输入的模型中应用这个技巧，在没有损失函数的情况下进行汇编，就像这样："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 988ms/step - loss: 1.0554 - binary_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dce9619490>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = keras.Input(shape=(3,), name=\"inputs\")\n",
    "targets = keras.Input(shape=(10,), name=\"targets\")\n",
    "logits = keras.layers.Dense(10)(inputs)\n",
    "predictions = LogisticEndpoint(name=\"predictions\")(logits, targets)\n",
    "\n",
    "model = keras.Model(inputs=[inputs, targets], outputs=predictions)\n",
    "model.compile(optimizer=\"adam\")  # No loss argument!\n",
    "\n",
    "data = {\n",
    "    \"inputs\": np.random.random((3, 3)),\n",
    "    \"targets\": np.random.random((3, 10)),\n",
    "}\n",
    "model.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information about training multi-input models, see the section Passing data to multi-input, multi-output models.\n",
    "\n",
    "想知道更多关于训练多输入模型的信息，请参考传递数据到多输入/输出模型部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatically setting apart a validation holdout set\n",
    "### 自动设置验证集\n",
    "\n",
    "In the first end-to-end example you saw, we used the validation_data argument to pass a tuple of NumPy arrays (x_val, y_val) to the model for evaluating a validation loss and validation metrics at the end of each epoch.\n",
    "\n",
    "Here's another option: the argument validation_split allows you to automatically reserve part of your training data for validation. The argument value represents the fraction of the data to be reserved for validation, so it should be set to a number higher than 0 and lower than 1. For instance, validation_split=0.2 means \"use 20% of the data for validation\", and validation_split=0.6 means \"use 60% of the data for validation\".\n",
    "\n",
    "The way the validation is computed is by taking the last x% samples of the arrays received by the fit() call, before any shuffling.\n",
    "\n",
    "Note that you can only use validation_split when training with NumPy data.\n",
    "\n",
    "在第一个端到端案例总，我们使用了验证参数将Numpy数组的元组（x_val, y_val）传递到模型，以在每次训练结束后评估验证集损失和验证集指标状态\n",
    "\n",
    "这里还有另一个选择：参数validation_split允许你自动的将部分训练集数据划分为验证集。参数的值意味着划分为验证集的数据比例。所以其取值在0到1之间。例如validation_split=0.2意味着将训练集的20%设置为验证集；而validation_split=0.6意味着将训练集的60%设置为验证集\n",
    "\n",
    "这里的验证方法是 在每次打乱顺序前，通过样本最后的x%数据传递给fit()并进行计算\n",
    "\n",
    "请注意，只有当输入是Numpy数据时，你才可以使用validation_split参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 3s 3ms/step - loss: 0.6173 - sparse_categorical_accuracy: 0.8291 - val_loss: 0.2491 - val_sparse_categorical_accuracy: 0.9218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dce98f7d30>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "model.fit(x_train, y_train, batch_size=64, validation_split=0.2, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notev学习笔记\n",
    "when you 'build' a model in Keras, it is not available to run. You must add the optimizer, loss, and metric to the model.\n",
    "\n",
    "there are many ways to do it.\n",
    "1. use compile() method to add optimizer, loss, and metric\n",
    "2. use add_loss() or add_metric() to add arguments respectively\n",
    "\n",
    "Also, even Keras has many build-in optimizers, losses, and metrics, we still can create cumtom iterm to deal with perticular problem\n",
    "\n",
    "In the end, if the input is Numpy array, we can use validation_split argument to set auto validation set\n",
    "\n",
    "当你“构建”好一个模型时，它还不能运行。你必须加入优化器，损失以及评价指标到模型中去\n",
    "\n",
    "有多种方式可以做到这一点：\n",
    "1. 通过compile（）方法来直接添加优化器，损失以及评价指标\n",
    "2. 或者通过add_loss()及add_metric() 等方法来依次添加这些元素\n",
    "\n",
    "另外，虽然Keras提供了丰富的内置优化器，损失，和指标，我们依然可以就具体问题来构建自定义的项目\n",
    "\n",
    "最后，如果模型的输入是Numpy数组形式的，我们可以通过validation_split参数来实现自动划分验证集。不需要提前对数据进行划分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & evaluation from tf.data Datasets\n",
    "## 训练和评估tf.data数据集\n",
    "\n",
    "In the past few paragraphs, you've seen how to handle losses, metrics, and optimizers, and you've seen how to use the validation_data and validation_split arguments in fit(), when your data is passed as NumPy arrays.\n",
    "\n",
    "Let's now take a look at the case where your data comes in the form of a tf.data.Dataset object.\n",
    "\n",
    "The tf.data API is a set of utilities in TensorFlow 2.0 for loading and preprocessing data in a way that's fast and scalable.\n",
    "\n",
    "For a complete guide about creating Datasets, see the [tf.data documentation](https://www.tensorflow.org/guide/data)\n",
    "\n",
    "在之前的内容中，你已经了解了如何控制损失函数、指标和优化器，并且知道了当传入的数据时Numpy数组时，如何使用validation_data和fit()方法的validation_split的参数（来对模型进行验证）\n",
    "\n",
    "现在来看看当输入数据的格式是tf.data.Dataset对象时，（要如何做）\n",
    "\n",
    "tf.data API是一系列TensorFlow2.0中的工具，用于以一种高速且可扩展的方式来加载和预处理数据\n",
    "\n",
    "关于创建数据集的完全指南，请参见[这里](https://www.tensorflow.org/guide/data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can pass a Dataset instance directly to the methods fit(), evaluate(), and predict\n",
    "\n",
    "你可以直接将tf.data数据集实例传递给 fit(), evaluate(), and predict方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.5486 - sparse_categorical_accuracy: 0.8423\n",
      "Epoch 2/3\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.1674 - sparse_categorical_accuracy: 0.9511\n",
      "Epoch 3/3\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.1196 - sparse_categorical_accuracy: 0.9640\n",
      "Evaluate\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1318 - sparse_categorical_accuracy: 0.9597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.13175071775913239,\n",
       " 'sparse_categorical_accuracy': 0.9596999883651733}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "# First, let's create a training Dataset instance.\n",
    "# 首先 创建一个训练集实例\n",
    "# For the sake of our example, we'll use the same MNIST data as before.\n",
    "# 为了方便，我们将使用之前的MNIST数据\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "# Shuffle and slice the dataset.\n",
    "# 打乱数据顺序并切片\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Now we get a test dataset.\n",
    "# 得到测试集\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_dataset = test_dataset.batch(64)\n",
    "\n",
    "# Since the dataset already takes care of batching,\n",
    "# we don't pass a `batch_size` argument.\n",
    "# 由于数据集已经的到了批量参数，所以我们不需要再次传递“batch_size”参数了\n",
    "model.fit(train_dataset, epochs=3)\n",
    "\n",
    "# You can also evaluate or predict on a dataset.\n",
    "# 你同样可以对这个数据集上进行评估和预测\n",
    "print(\"Evaluate\")\n",
    "result = model.evaluate(test_dataset)\n",
    "dict(zip(model.metrics_names, result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the Dataset is reset at the end of each epoch, so it can be reused of the next epoch.\n",
    "\n",
    "If you want to run training only on a specific number of batches from this Dataset, you can pass the steps_per_epoch argument, which specifies how many training steps the model should run using this Dataset before moving on to the next epoch.\n",
    "\n",
    "If you do this, the dataset is not reset at the end of each epoch, instead we just keep drawing the next batches. The dataset will eventually run out of data (unless it is an infinitely-looping dataset).\n",
    "\n",
    "\n",
    "注意：数据集会在每次训练结束后被重置，所以数据集可以在下一次的训练中被复用（虽然是同一个数据集，但是作为训练集的数据，训练集中每一个批次的数据都不一样）\n",
    "\n",
    "如果你想以一种特定次序的数据集批次来进行训练，你可以使用the steps_per_epoch参数。这个参数会指定模型在这一次的训练中的批量数目\n",
    "\n",
    "如果你这么做的话，数据集不会在训练结束后重置，取而代之的是我们将持续的重训练集中抽出下一个训练用批次，直到所有的数据都被抽取（除非这是一个无限循环的数据集）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "100/100 [==============================] - 2s 3ms/step - loss: 1.2173 - sparse_categorical_accuracy: 0.6601\n",
      "Epoch 2/3\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.4022 - sparse_categorical_accuracy: 0.8857\n",
      "Epoch 3/3\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3559 - sparse_categorical_accuracy: 0.8940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dceabae520>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "# Prepare the training dataset\n",
    "# 准备训练集\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Only use the 100 batches per epoch (that's 64 * 100 samples)\n",
    "#每次训练只使用100个批量\n",
    "model.fit(train_dataset, epochs=3, steps_per_epoch=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a validation dataset\n",
    "### 使用验证数据集\n",
    "You can pass a Dataset instance as the validation_data argument in fit():\n",
    "\n",
    "你可以将（验证集）实例通过fit()中的alidation_data参数来传递"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "# Prepare the training dataset\n",
    "# 准备训练集\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Prepare the validation dataset\n",
    "# 准备验证集\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(64)\n",
    "\n",
    "model.fit(train_dataset, epochs=1, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of each epoch, the model will iterate over the validation dataset and compute the validation loss and validation metrics.\n",
    "\n",
    "在每次训练结束后，模型会对验证集数据进行迭代并计算验证损失和验证指标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to run validation only on a specific number of batches from this dataset, you can pass the validation_steps argument, which specifies how many validation steps the model should run with the validation dataset before interrupting validation and moving on to the next epoch:\n",
    "\n",
    "如果你喜欢指定每次验证时使用的批次数量，你可以传递validation_steps 参数来做到这一点。这个参数指定了每次训练结束后，有多少验证集批次会被执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 3s 2ms/step - loss: 0.5671 - sparse_categorical_accuracy: 0.8397 - val_loss: 0.3034 - val_sparse_categorical_accuracy: 0.9109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dc816a75e0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "# Prepare the training dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Prepare the validation dataset\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(64)\n",
    "\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    epochs=1,\n",
    "    # Only run validation using the first 10 batches of the dataset\n",
    "    # using the `validation_steps` argument\n",
    "    # 因为validation_steps参数的设定，每次只使用数据集的前10个批次进行验证\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the validation dataset will be reset after each use (so that you will always be evaluating on the same samples from epoch to epoch).\n",
    "\n",
    "The argument validation_split (generating a holdout set from the training data) is not supported when training from Dataset objects, since this feature requires the ability to index the samples of the datasets, which is not possible in general with the Dataset API.\n",
    "\n",
    "注意，每次模型训练结束后，验证集都会被重置，（所以你会使用相同的样本对每一次的训练模型进行验证）\n",
    "\n",
    "当训练来自tf数据集对象时，参数validation_split（从训练集中生成验证集）不被支持。这是因为这个功能需要索引数据集中的样本，而由数据集API生成的对象并不能做到这一点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note 学习笔记\n",
    "\n",
    "this part shows how to train, evaluate, and predict with tf.data dataset object.\n",
    "\n",
    "In my opinion, the similar thing is they can be created directly by fucntions. and the differece thing is that tf dataset can set batch size in advance\n",
    "\n",
    "Also, this part present how the input is used in the training processing. In general, the input data will be shuffled and split into several batches. then model will learning from these batches. when model learning all data in input dataset in this way, we can say the model finish a epoch.\n",
    "\n",
    "somethings, we want to pick sample from input in a certain pattern, there are some argument that can help us implement this feature\n",
    "\n",
    "like XGBoost, I can add train set and validation set into model at the same time. and the model will report the loss and metric on the validation set. In addition, I also can set the sample pick pattern on the validation set.\n",
    "\n",
    "这一部分展示了对一个tf数据集格式的输入进行训练，评估和预测\n",
    "\n",
    "在我看来，两者的相似之处是它们都可以用过函数进行创建。不同之处在于在创建tf数据集对象时可以提前设定批量规模\n",
    "\n",
    "此外，这一部分还展示了模型的训练过程是如何使用输入数据的。一般来说，输入数据会被打乱并划分为多个批量数据。然后模型会从这些批量数据中进行学习。当模型以这种方式“学习完”全部数据后，我们称之为魔形女完成了一次训练\n",
    "\n",
    "有时，我们希望以某些特定的方式来选择桑本数据。这时可以通过一些参数设置来实现这一功能\n",
    "\n",
    "\n",
    "类似于XGBoost， 我可以同时把训练集和验证集数据加入模型。模型会报告验证集上的损失和指标信息。另外，我依然可以指定从验证集从提取数据的方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other input formats supported\n",
    "## 其他支持的输入格式\n",
    "Besides NumPy arrays, eager tensors, and TensorFlow Datasets, it's possible to train a Keras model using Pandas dataframes, or from Python generators that yield batches of data & labels.\n",
    "\n",
    "In particular, the keras.utils.Sequence class offers a simple interface to build Python data generators that are multiprocessing-aware and can be shuffled.\n",
    "\n",
    "In general, we recommend that you use:\n",
    "1. NumPy input data if your data is small and fits in memory\n",
    "2. Dataset objects if you have large datasets and you need to do distributed training\n",
    "3. Sequence objects if you have large datasets and you need to do a lot of custom Python-side processing that cannot be done in TensorFlow (e.g. if you rely on external libraries for data loading or preprocessing).\n",
    "\n",
    "除了NumPy arrays, eager tensors, 和TensorFlow Datasets三类输入格式以外，Keras模型还支持pandas数据框或者能生成批量数据/标签的python生成器\n",
    "\n",
    "具体来说，keras.utils.Sequence 类提供了为数据生成器提供了一个简单的接口。这些生成器通常是多进程感知的（multiprocessing-aware）并且支持数据打乱/洗牌\n",
    "\n",
    "一般来说，我们建议你使用：\n",
    "1.Numpy输入，如果数据规模小且可以在内存中训练\n",
    "2.数据集对象，如果你的数据规模很大并且你需要使用分布式训练\n",
    "3.顺序对象，如果你的数据规模很大并且你需要使用大量自定义的处理流程。这些流程无法由Tensorflow完成（如需要依赖其他的数据加载与处理包）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a keras.utils.Sequence object as input\n",
    "## 将keras.utils.Sequence对象作为输入\n",
    "\n",
    "keras.utils.Sequence is a utility that you can subclass to obtain a Python generator with two important properties:\n",
    "1. It works well with multiprocessing.\n",
    "2. It can be shuffled (e.g. when passing shuffle=True in fit()).\n",
    "\n",
    "A Sequence must implement two methods:\n",
    "1. \\__getitem__\n",
    "2. \\__len__\n",
    "\n",
    "The method __getitem__ should return a complete batch. If you want to modify your dataset between epochs, you may implement on_epoch_end.\n",
    "\n",
    "keras.utils.Sequence是一个可以让你创建子类来生成python生成器的工具。这个工具有两个重要特点：\n",
    "1. 它在多进程条件下顺利工作\n",
    "2. 它支持打乱/洗牌操作\n",
    "\n",
    "一个Sequence对象必须要实现两个方法：\n",
    "1. \\__getitem\\__\n",
    "2. \\__len\\__\n",
    "\n",
    "\\__getitem\\__方法会返回一个完整的批量数据。如果你希望在两次训练期间调整数据集，你可以使用on_epoch_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a quick example\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "\n",
    "# Here, `filenames` is list of path to the images\n",
    "# and `labels` are the associated labels.\n",
    "#在这里，`filenames`是图像的路径信息列表，而`labels`是相对应的标签信息\n",
    "\n",
    "class CIFAR10Sequence(Sequence):\n",
    "    def __init__(self, filenames, labels, batch_size):\n",
    "        self.filenames, self.labels = filenames, labels\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.filenames) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return np.array([\n",
    "            resize(imread(filename), (200, 200))\n",
    "               for filename in batch_x]), np.array(batch_y)\n",
    "\n",
    "sequence = CIFAR10Sequence(filenames, labels, batch_size)\n",
    "model.fit(sequence, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using sample weighting and class weighting\n",
    "## 使用样本权重和类别权重\n",
    "\n",
    "With the default settings the weight of a sample is decided by its frequency in the dataset. There are two methods to weight the data, independent of sample frequency:\n",
    "\n",
    "1. Class weights\n",
    "2. Sample weights\n",
    "\n",
    "在默认设置中，一个样本的模型权重由它在数据集中出现的频率决定。有两个方法可以无视数据频率对数据进行加权：\n",
    "1. 类别权重\n",
    "2. 样本权重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class weights\n",
    "### 类别权重\n",
    "This is set by passing a dictionary to the class_weight argument to Model.fit(). This dictionary maps class indices to the weight that should be used for samples belonging to this class.\n",
    "\n",
    "This can be used to balance classes without resampling, or to train a model that gives more importance to a particular class.\n",
    "\n",
    "For instance, if class \"0\" is half as represented as class \"1\" in your data, you could use Model.fit(..., class_weight={0: 1., 1: 0.5}).\n",
    "\n",
    "\n",
    "设置类别权重的方法是 传递一个字典对象给class_weight参数，然后这个参数把权重传递给 Model.fit()，这个字典将类别和权重对应，这样属于这个类别的的样本都可以使用所设定的权重\n",
    "\n",
    "这可以在不进行重新取样的前提下平衡类别，或者是在指定一个重要类别的条件下对模型进行训练\n",
    "\n",
    "例如，如果你的样本中，0类别只有1累呗的一半，那么你可以设置为 Model.fit(..., class_weight={0: 1., 1: 0.5})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a NumPy example where we use class weights or sample weights to give more importance to the correct classification of class \\#5 (which is the digit \"5\" in the MNIST dataset).\n",
    "\n",
    "这是是一个Numpy数据集示例。我们通过调节类别和样本权重来给正确预测数字5一个更高的重要性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit with class weight\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.6325 - sparse_categorical_accuracy: 0.8372\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dc842880d0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class_weight = {\n",
    "    0: 1.0,\n",
    "    1: 1.0,\n",
    "    2: 1.0,\n",
    "    3: 1.0,\n",
    "    4: 1.0,\n",
    "    # Set weight \"2\" for class \"5\",\n",
    "    # making this class 2x more important\n",
    "    5: 2.0,\n",
    "    6: 1.0,\n",
    "    7: 1.0,\n",
    "    8: 1.0,\n",
    "    9: 1.0,\n",
    "}\n",
    "\n",
    "print(\"Fit with class weight\")\n",
    "model = get_compiled_model()\n",
    "model.fit(x_train, y_train, class_weight=class_weight, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample weights\n",
    "### 样本权重\n",
    "\n",
    "For fine grained control, or if you are not building a classifier, you can use \"sample weights\".\n",
    "\n",
    "1. When training from NumPy data: Pass the sample_weight argument to Model.fit().\n",
    "2. When training from tf.data or any other sort of iterator: Yield (input_batch, label_batch, sample_weight_batch) tuples.\n",
    "\n",
    "A \"sample weights\" array is an array of numbers that specify how much weight each sample in a batch should have in computing the total loss. It is commonly used in imbalanced classification problems (the idea being to give more weight to rarely-seen classes).\n",
    "\n",
    "When the weights used are ones and zeros, the array can be used as a mask for the loss function (entirely discarding the contribution of certain samples to the total loss).\n",
    "\n",
    "为了控制颗粒度，或者你还没有建立一个分类器的情况下，你可以使用样本权重\n",
    "\n",
    "1. 对Numpy数据进行训练时，传递sample_weight给Model.fit()\n",
    "2. 对tf.data数据或者其他类型迭代器进行训练时，生成 (input_batch, label_batch, sample_weight_batch)元组\n",
    "\n",
    "一个样本权重数组时一组用户指定批量数据中每一个样本权重的数组，这个权重会被用户计算整体的损失。这一功能常被用于不平衡分类问题之中（给不常见的类别更高的权重）\n",
    "\n",
    "当权重是0和1时，这个权重数组可以用作损失函数的掩码（可以完全忽略特定样本对总体损失的贡献）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit with sample weight\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.6528 - sparse_categorical_accuracy: 0.8264\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dc8463f280>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_weight = np.ones(shape=(len(y_train),))\n",
    "sample_weight[y_train == 5] = 2.0\n",
    "\n",
    "print(\"Fit with sample weight\")\n",
    "model = get_compiled_model()\n",
    "model.fit(x_train, y_train, sample_weight=sample_weight, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 3s 2ms/step - loss: 0.5916 - sparse_categorical_accuracy: 0.8478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dc8499df70>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a matching Dataset example\n",
    "# 一个匹配数据集案例\n",
    "sample_weight = np.ones(shape=(len(y_train),))\n",
    "sample_weight[y_train == 5] = 2.0\n",
    "\n",
    "# Create a Dataset that includes sample weights\n",
    "# 构建一个含有样本权重的数据集\n",
    "# (3rd element in the return tuple).\n",
    "#（元组中的第三个元素即是样本权重）\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train, sample_weight))\n",
    "\n",
    "# Shuffle and slice the dataset.\n",
    "# 打乱并切片数据\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "model = get_compiled_model()\n",
    "model.fit(train_dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note 学习笔记\n",
    "like my comment about model weights in the Functional API part, I believe this is a good way to deal with model bias problem\n",
    "\n",
    "像我在函数式API部分对模型权重的评论一样，我相信这（手动分配权重）是解决模型偏见的一个好办法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passing data to multi-input, multi-output models\n",
    "## 传递数据给多输入/输出模型\n",
    "\n",
    "In the previous examples, we were considering a model with a single input (a tensor of shape (764,)) and a single output (a prediction tensor of shape (10,)). But what about models that have multiple inputs or outputs?\n",
    "\n",
    "Consider the following model, which has an image input of shape (32, 32, 3) (that's (height, width, channels)) and a time series input of shape (None, 10) (that's (timesteps, features)). Our model will have two outputs computed from the combination of these inputs: a \"score\" (of shape (1,)) and a probability distribution over five classes (of shape (5,)).\n",
    "\n",
    "在之前的示例中，我们只考虑了只有一个输入/输出的模型。但是对于有多个输入/输出的模型，又应该如何对其进行操作呢？\n",
    "\n",
    "考虑以下模型：图像输入的维度是(32, 32, 3) （即长度，宽度，通道），时间序列输入的维度是（None,10）(即时间戳，特征)。我们的模型将从这些输入组合中生成两个输出：得分（维度是（1,））和5个类别的分布概率（维度是（5，））\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input = keras.Input(shape=(32, 32, 3), name=\"img_input\")\n",
    "timeseries_input = keras.Input(shape=(None, 10), name=\"ts_input\")\n",
    "\n",
    "x1 = layers.Conv2D(3, 3)(image_input)\n",
    "x1 = layers.GlobalMaxPooling2D()(x1)\n",
    "\n",
    "x2 = layers.Conv1D(3, 3)(timeseries_input)\n",
    "x2 = layers.GlobalMaxPooling1D()(x2)\n",
    "\n",
    "x = layers.concatenate([x1, x2])\n",
    "\n",
    "score_output = layers.Dense(1, name=\"score_output\")(x)\n",
    "class_output = layers.Dense(5, name=\"class_output\")(x)\n",
    "\n",
    "model = keras.Model(\n",
    "    inputs=[image_input, timeseries_input], outputs=[score_output, class_output]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot this model, so you can clearly see what we're doing here (note that the shapes shown in the plot are batch shapes, rather than per-sample shapes).\n",
    "\n",
    "让我们绘制模型的层次图，这样就能清晰地了解我们正在做什么（注意图中展示的维度是批量数据的维度，而不是我们之前的样本维度）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"multi_input_and_output_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify different losses to different outputs, by passing the loss functions as a list\n",
    "# 通过将损失函数列表来指定不同的损失函数\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=[keras.losses.MeanSquaredError(), keras.losses.CategoricalCrossentropy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we only passed a single loss function to the model, the same loss function would be applied to every output (which is not appropriate here).\n",
    "\n",
    "如果你只传递了一个损失函数，那么这个函数会被应用于所有的输出（并不适用于目前的示例，因为计算得分是一个回归问题，计算类别概率是一个分类问题）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=[keras.losses.MeanSquaredError(), keras.losses.CategoricalCrossentropy()],\n",
    "    metrics=[\n",
    "        [\n",
    "            keras.metrics.MeanAbsolutePercentageError(),\n",
    "            keras.metrics.MeanAbsoluteError(),\n",
    "        ],\n",
    "        [keras.metrics.CategoricalAccuracy()],\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we gave names to our output layers, we could also specify per-output losses and metrics via a dict:\n",
    "\n",
    "由于我们给每一个输出层命名了，所以我们可以通过字典来提前指定损失函数和指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss={\n",
    "        \"score_output\": keras.losses.MeanSquaredError(),\n",
    "        \"class_output\": keras.losses.CategoricalCrossentropy(),\n",
    "    },\n",
    "    metrics={\n",
    "        \"score_output\": [\n",
    "            keras.metrics.MeanAbsolutePercentageError(),\n",
    "            keras.metrics.MeanAbsoluteError(),\n",
    "        ],\n",
    "        \"class_output\": [keras.metrics.CategoricalAccuracy()],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recommend the use of explicit names and dicts if you have more than 2 outputs.\n",
    "\n",
    "It's possible to give different weights to different output-specific losses (for instance, one might wish to privilege the \"score\" loss in our example, by giving to 2x the importance of the class loss), using the loss_weights argument:\n",
    "\n",
    "我们建议，当你有2个及以上的输出时，采用名字和字典（来传递损失函数和指标参数）\n",
    "\n",
    "通过loss_weights参数给不同的输出类别不同的权重也是可行的（比如，可以给分数损失更高的优先级，可以给于这类损失两倍的权重）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss={\n",
    "        \"score_output\": keras.losses.MeanSquaredError(),\n",
    "        \"class_output\": keras.losses.CategoricalCrossentropy(),\n",
    "    },\n",
    "    metrics={\n",
    "        \"score_output\": [\n",
    "            keras.metrics.MeanAbsolutePercentageError(),\n",
    "            keras.metrics.MeanAbsoluteError(),\n",
    "        ],\n",
    "        \"class_output\": [keras.metrics.CategoricalAccuracy()],\n",
    "    },\n",
    "    loss_weights={\"score_output\": 2.0, \"class_output\": 1.0},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could also choose not to compute a loss for certain outputs, if these outputs are meant for prediction but not for training:\n",
    "\n",
    "你也可以选择不计算某些输出的损失，如果这些输出不是为了训练合适为了预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List loss version\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=[None, keras.losses.CategoricalCrossentropy()],\n",
    ")\n",
    "\n",
    "# Or dict loss version\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss={\"class_output\": keras.losses.CategoricalCrossentropy()},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing data to a multi-input or multi-output model in fit() works in a similar way as specifying a loss function in compile: you can pass lists of NumPy arrays (with 1:1 mapping to the outputs that received a loss function) or dicts mapping output names to NumPy arrays.\n",
    "\n",
    "类似与指定compile（）方法的损失函数，通过fit()发放传递数据给多输入/输出模型也是类似的： 你可以传递Numpy数组列表（与接受损失函数的输出一一对应）或者字典（将输出的名称映射到Numpy数组）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 9ms/step - loss: 10.8368 - score_output_loss: 0.2767 - class_output_loss: 10.5601\n",
      "4/4 [==============================] - 1s 8ms/step - loss: 10.3543 - score_output_loss: 0.1203 - class_output_loss: 10.2341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dc81c26e80>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=[keras.losses.MeanSquaredError(), keras.losses.CategoricalCrossentropy()],\n",
    ")\n",
    "\n",
    "# Generate dummy NumPy data\n",
    "img_data = np.random.random_sample(size=(100, 32, 32, 3))\n",
    "ts_data = np.random.random_sample(size=(100, 20, 10))\n",
    "score_targets = np.random.random_sample(size=(100, 1))\n",
    "class_targets = np.random.random_sample(size=(100, 5))\n",
    "\n",
    "# Fit on lists\n",
    "model.fit([img_data, ts_data], [score_targets, class_targets], batch_size=32, epochs=1)\n",
    "\n",
    "# Alternatively, fit on dicts\n",
    "model.fit(\n",
    "    {\"img_input\": img_data, \"ts_input\": ts_data},\n",
    "    {\"score_output\": score_targets, \"class_output\": class_targets},\n",
    "    batch_size=32,\n",
    "    epochs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the Dataset use case: similarly as what we did for NumPy arrays, the Dataset should return a tuple of dicts.\n",
    "\n",
    "这是一个使用tf数据集对象的示例，和使用Numpy数组的示例非常相似。数据集对象会返回格式是包含字典的元组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 19ms/step - loss: 10.2988 - score_output_loss: 0.1096 - class_output_loss: 10.1892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dc87936e50>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (\n",
    "        {\"img_input\": img_data, \"ts_input\": ts_data},\n",
    "        {\"score_output\": score_targets, \"class_output\": class_targets},\n",
    "    )\n",
    ")\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    " model.fit(train_dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note 学习笔记\n",
    "\n",
    "this part shows how to train/evaluate/predict a multiple input/output model.\n",
    "\n",
    "because model has multiple output, so we can set different optimizer, metric, and loss for different output layers. And if we just set one optimizer, metric, and loss. the setting will be applied for all output layers\n",
    "\n",
    "If we want to set multiple optimizers, metrics, and losses, they are two ways:\n",
    "1. use list to pass the seting to compile()\n",
    "2. create a dictionary object to mapping value based on layer name\n",
    "\n",
    "What's more, if we use dictionary to do this, we must know the layer name. So it is important to give layer a good name\n",
    "\n",
    "这一部分展示了如何训练/评估/预测一个多输入输出模型\n",
    "\n",
    "因为模型有多个输出，所以我们可以为不同的输出层设置不一样的优化器，损失函数和评估指标。如果我们只设定了一个优化器，损失函数和评估指标，那么这个优化器，损失函数和评估指标会被应用于所有的输出层\n",
    "\n",
    "如果我们想要设置多个优化器，损失函数和评估指标，有两种方式：\n",
    "1. 在compile（）方法中通过列表来指定\n",
    "2. 创建一个字典对象，实现层名称和具体设定值之间的映射\n",
    "\n",
    "更重要的是，如果我们采用字典来实现这一过程，那么我们必须知道层的名称。因此，给层一个好的名称十分重要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using callbacks\n",
    "## 使用回调\n",
    "\n",
    "Callbacks in Keras are objects that are called at different points during training (at the start of an epoch, at the end of a batch, at the end of an epoch, etc.). They can be used to implement certain behaviors, such as:\n",
    "1. Doing validation at different points during training (beyond the built-in per-epoch validation)\n",
    "2. Checkpointing the model at regular intervals or when it exceeds a certain accuracy threshold\n",
    "3. Changing the learning rate of the model when training seems to be plateauing\n",
    "4. Doing fine-tuning of the top layers when training seems to be plateauing\n",
    "5. Sending email or instant message notifications when training ends or where a certain performance threshold is exceeded\n",
    "6. Etc.\n",
    "\n",
    "在Keras中，回调是一类于调用时机与训练完全相反的对象（始于训练结束，而终于批量数据）它们被用于实现特定的行为，比如：\n",
    "1. 在训练中不同的时机对模型进行验证（不是在每次训练结束后验证）\n",
    "2. 间隔一定时间或者当模型超过了设定的准确性门槛时，设置检查点\n",
    "3. 当模型训练结果趋于平缓时，改变模型的学习率\n",
    "4. 当模型训练结果区域平缓时，对顶部层进行调参\n",
    "5. 当训练结束或表现达到设定的门槛值时，发送邮件或特定的提示信息\n",
    "6. 其他"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.6162 - sparse_categorical_accuracy: 0.8313 - val_loss: 0.2368 - val_sparse_categorical_accuracy: 0.9274\n",
      "Epoch 2/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.1928 - sparse_categorical_accuracy: 0.9431 - val_loss: 0.1857 - val_sparse_categorical_accuracy: 0.9450\n",
      "Epoch 3/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.1326 - sparse_categorical_accuracy: 0.9618 - val_loss: 0.1639 - val_sparse_categorical_accuracy: 0.9501\n",
      "Epoch 4/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.1022 - sparse_categorical_accuracy: 0.9692 - val_loss: 0.1485 - val_sparse_categorical_accuracy: 0.9548\n",
      "Epoch 5/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.0839 - sparse_categorical_accuracy: 0.9741 - val_loss: 0.1428 - val_sparse_categorical_accuracy: 0.9588\n",
      "Epoch 6/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.0681 - sparse_categorical_accuracy: 0.9789 - val_loss: 0.1408 - val_sparse_categorical_accuracy: 0.9617\n",
      "Epoch 00006: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dc88c53df0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Callbacks can be passed as a list to your call to fit()\n",
    "# 回调函数可以像列表一样传递给fit()\n",
    "model = get_compiled_model()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        # Stop training when `val_loss` is no longer improving\n",
    "        # 当验证器表现不再提升时，停止训练\n",
    "        monitor=\"val_loss\",\n",
    "        # \"no longer improving\" being defined as \"no better than 1e-2 less\"\n",
    "        # “不再提升”意味着提升分数不超过1e-2\n",
    "        min_delta=1e-2,\n",
    "        # \"no longer improving\" being further defined as \"for at least 2 epochs\"\n",
    "        # “不再提升”意味着比较最近两次训练的结果\n",
    "        patience=2,\n",
    "        verbose=1,\n",
    "    )\n",
    "]\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    "    validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Many built-in callbacks are available\n",
    "### 一些可用的内置回调函数\n",
    "\n",
    "There are many built-in callbacks already available in Keras, such as:\n",
    "1. ModelCheckpoint: Periodically save the model.\n",
    "2. EarlyStopping: Stop training when training is no longer improving the validation metrics.\n",
    "3. TensorBoard: periodically write model logs that can be visualized in TensorBoard (more details in the section \"Visualization\").\n",
    "4. CSVLogger: streams loss and metrics data to a CSV file.\n",
    "5. etc.\n",
    "\n",
    "See the [callbacks documentation](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/) for the complete list.\n",
    "\n",
    "这里是一些Keras内置的回调函数：\n",
    "1. ModelCheckpoint：周期性的保存模型\n",
    "2. EarlyStopping：停止训练当训练不再提升验证指标\n",
    "3. TensorBoard：周期性的记录模型日志并在TensorBoard中显示（更多细节参见“可视化”部分）\n",
    "4. CSVLogger：将损失和指标数据保存为CSV文件\n",
    "5. 其他\n",
    "\n",
    "通过[回调函数文档](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/)来查阅完整的函数列表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing your own callback\n",
    "### 编写你自己的回调函数\n",
    "You can create a custom callback by extending the base class keras.callbacks.Callback. A callback has access to its associated model through the class property self.model.\n",
    "\n",
    "Make sure to read the [complete guide to writing custom callbacks](https://www.tensorflow.org/guide/keras/custom_callback/).\n",
    "\n",
    "Here's a simple example saving a list of per-batch loss values during training:\n",
    "\n",
    "你可以创建自定义的回调函数来扩充keras.callbacks.Callback类，一个回调函数可以通过类数据self.model来关联模型\n",
    "\n",
    "确保已经阅读了[编写自定义回调函数(完全版)](https://www.tensorflow.org/guide/keras/custom_callback/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        self.per_batch_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note 学习笔记\n",
    "\n",
    "This and following part show the power of callback object\n",
    "\n",
    "In my opinion, the thing is that each part of a model only know the inforamtion from three channels: its input, output, and argument setting. Therefore, we cannot implement some feature because the related part don't know this information it need.\n",
    "\n",
    "To solve this problem, we can uss the callback function. The callback object is a special part of models. it is not necessary for model, but it can access to all information in the model. So, we can implement some feature other method or fucntion cannot do by callback object, such as check point, learning rate decay, and logs visualization.\n",
    "\n",
    "\n",
    "这一部分以及后续部分展示了回调函数的强大功能\n",
    "\n",
    "在我看来，事情是这样的：模型的每一部分都只能从三个渠道来获取信息：他们的输入，他们的输出，以及设定的参数。因此，因为相关的模型组成部分无法获得必要的信息，我们可能无法实现某些功能。\n",
    "\n",
    "为了解决这一问题，我们可以用到回调函数。回调函数是一种特别的模型组成部分：它不是必须的，但是它可以访问模型中的所有信息，因此，我们可以通过回调函数实现哪些其他方法和函数无法实现的功能，诸如检查点设置，学习率衰退，以及模型日志的可视化。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpointing models\n",
    "## 检查点模型\n",
    "When you're training model on relatively large datasets, it's crucial to save checkpoints of your model at frequent intervals.\n",
    "\n",
    "The easiest way to achieve this is with the ModelCheckpoint callback:\n",
    "\n",
    "当你训练一个大型数据集时，频繁的保存你的模型检查点至关重要\n",
    "\n",
    "实现这一功能的最简便的办法是使用ModelCheckpoint回调函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "625/625 [==============================] - 3s 3ms/step - loss: 0.6059 - sparse_categorical_accuracy: 0.8337 - val_loss: 0.2245 - val_sparse_categorical_accuracy: 0.9319\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.22450, saving model to mymodel_1\n",
      "INFO:tensorflow:Assets written to: mymodel_1\\assets\n",
      "Epoch 2/2\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.1918 - sparse_categorical_accuracy: 0.9434 - val_loss: 0.1901 - val_sparse_categorical_accuracy: 0.9437\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.22450 to 0.19015, saving model to mymodel_2\n",
      "INFO:tensorflow:Assets written to: mymodel_2\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dc88fce910>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        # Path where to save the model\n",
    "        # 保存路径\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_loss` score has improved.\n",
    "        # 以下两个参数意味着当模型指标（`val_loss` ）提升时，我们将覆盖最近的检查点\n",
    "        # The saved model name will include the current epoch.\n",
    "        # 保存的模型名称中包含当前的训练次数\n",
    "        filepath=\"mymodel_{epoch}\",\n",
    "        save_best_only=True,  # Only save a model if `val_loss` has improved.\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=1,\n",
    "    )\n",
    "]\n",
    "model.fit(\n",
    "    x_train, y_train, epochs=2, batch_size=64, callbacks=callbacks, validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ModelCheckpoint callback can be used to implement fault-tolerance: the ability to restart training from the last saved state of the model in case training gets randomly interrupted. Here's a basic example:\n",
    "\n",
    "\n",
    "ModelCheckpoint回调函数可以用于实现模型的容错性：从上一次保存的状态继续训练模型以防止训练过程被随机打断。以下是一个基本示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new model\n",
      "  87/1563 [>.............................] - ETA: 4s - loss: 1.5473 - sparse_categorical_accuracy: 0.5351INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=1.05\\assets\n",
      " 177/1563 [==>...........................] - ETA: 19s - loss: 1.2287 - sparse_categorical_accuracy: 0.6377INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.73\\assets\n",
      " 298/1563 [====>.........................] - ETA: 21s - loss: 1.0099 - sparse_categorical_accuracy: 0.7058INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.62\\assets\n",
      " 397/1563 [======>.......................] - ETA: 24s - loss: 0.9028 - sparse_categorical_accuracy: 0.7383INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.54\\assets\n",
      " 485/1563 [========>.....................] - ETA: 23s - loss: 0.8336 - sparse_categorical_accuracy: 0.7590INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.49\\assets\n",
      " 592/1563 [==========>...................] - ETA: 22s - loss: 0.7688 - sparse_categorical_accuracy: 0.7781INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.45\\assets\n",
      " 697/1563 [============>.................] - ETA: 20s - loss: 0.7194 - sparse_categorical_accuracy: 0.7925INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.43\\assets\n",
      " 788/1563 [==============>...............] - ETA: 18s - loss: 0.6844 - sparse_categorical_accuracy: 0.8027INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.41\\assets\n",
      " 894/1563 [================>.............] - ETA: 15s - loss: 0.6504 - sparse_categorical_accuracy: 0.8125INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.39\\assets\n",
      " 981/1563 [=================>............] - ETA: 14s - loss: 0.6266 - sparse_categorical_accuracy: 0.8194INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.37\\assets\n",
      "1096/1563 [====================>.........] - ETA: 11s - loss: 0.5993 - sparse_categorical_accuracy: 0.8273INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.36\\assets\n",
      "1188/1563 [=====================>........] - ETA: 9s - loss: 0.5803 - sparse_categorical_accuracy: 0.8328INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.35\\assets\n",
      "1295/1563 [=======================>......] - ETA: 6s - loss: 0.5605 - sparse_categorical_accuracy: 0.8385INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.33\\assets\n",
      "1389/1563 [=========================>....] - ETA: 4s - loss: 0.5449 - sparse_categorical_accuracy: 0.8430INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.33\\assets\n",
      "1495/1563 [===========================>..] - ETA: 1s - loss: 0.5292 - sparse_categorical_accuracy: 0.8475INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.32\\assets\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 0.5197 - sparse_categorical_accuracy: 0.8502\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dc8a781880>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Prepare a directory to store all the checkpoints.\n",
    "# 准备一个字典来储存所有的检查点\n",
    "checkpoint_dir = \"./ckpt\"\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "\n",
    "def make_or_restore_model():\n",
    "    # Either restore the latest model, or create a fresh one\n",
    "    # 恢复最近的模型，或者在没有检查点可用时，创造一个新的模型\n",
    "    # if there is no checkpoint available.\n",
    "    checkpoints = [checkpoint_dir + \"/\" + name for name in os.listdir(checkpoint_dir)]\n",
    "    if checkpoints:\n",
    "        latest_checkpoint = max(checkpoints, key=os.path.getctime)\n",
    "        print(\"Restoring from\", latest_checkpoint)\n",
    "        return keras.models.load_model(latest_checkpoint)\n",
    "    print(\"Creating a new model\")\n",
    "    return get_compiled_model()\n",
    "\n",
    "\n",
    "model = make_or_restore_model()\n",
    "callbacks = [\n",
    "    # This callback saves a SavedModel every 100 batches.\n",
    "    # We include the training loss in the saved model name.\n",
    "    # 这个回调函数会每经过100个批量数据就保存一次模型，保存的模型名称中包含训练集损失\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_dir + \"/ckpt-loss={loss:.2f}\", save_freq=100\n",
    "    )\n",
    "]\n",
    "model.fit(x_train, y_train, epochs=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You call also write your own callback for saving and restoring models.\n",
    "\n",
    "For a complete guide on serialization and saving, see [the guide to saving and serializing Models](https://www.tensorflow.org/guide/keras/save_and_serialize/).\n",
    "\n",
    "你也可以自己编写回调函数来保存和回复模型\n",
    "\n",
    "要保证的序列化和保存（模型），请参考[这边指南](https://www.tensorflow.org/guide/keras/save_and_serialize/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using learning rate schedules\n",
    "## 使用学习率设定函数\n",
    "A common pattern when training deep learning models is to gradually reduce the learning as training progresses. This is generally known as \"learning rate decay\".\n",
    "\n",
    "The learning decay schedule could be static (fixed in advance, as a function of the current epoch or the current batch index), or dynamic (responding to the current behavior of the model, in particular the validation loss).\n",
    "\n",
    "一个训练深度学习模型的常见范式是逐步减少学习率，即学习率衰减\n",
    "\n",
    "学习率衰减函数可是静态（开始是固定的学习率，类似一个基于最近的训练次数和批量次数的函数）或者动态的（对模型最近的行为产生反应，一般而言是对验证集损失产生反应）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing a schedule to an optimizer\n",
    "### 传递一个设定函数给优化器\n",
    "You can easily use a static learning rate decay schedule by passing a schedule object as the learning_rate argument in your optimizer:\n",
    "\n",
    "你可以轻易地将静态学习率衰减函数作为learning_rate参数传递给优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.1\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
    ")\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several built-in schedules are available: ExponentialDecay, PiecewiseConstantDecay, PolynomialDecay, and InverseTimeDecay.\n",
    "\n",
    "一些内置的衰减函数：ExponentialDecay, PiecewiseConstantDecay, PolynomialDecay, and InverseTimeDecay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using callbacks to implement a dynamic learning rate schedule\n",
    "### 利用回调函数应用动态学习率衰减设定函数\n",
    "A dynamic learning rate schedule (for instance, decreasing the learning rate when the validation loss is no longer improving) cannot be achieved with these schedule objects, since the optimizer does not have access to validation metrics.\n",
    "\n",
    "However, callbacks do have access to all metrics, including validation metrics! You can thus achieve this pattern by using a callback that modifies the current learning rate on the optimizer. In fact, this is even built-in as the ReduceLROnPlateau callback.\n",
    "\n",
    "动态学习率衰减设定（例如，当验证集损失不在减少时，降低学习率）无法通过设定优化器参数来实现，因为优化器不知道验证集指标\n",
    "\n",
    "然而，回调函数可以访问所有的指标，包括验证集指标！ 你可以通过使用回调函数来调整优化器中的学习率参数。实际上，这一功能已经成为了一个内置回调函数ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing loss and metrics during training\n",
    "## 训练过程中的损失和指标可视化\n",
    "The best way to keep an eye on your model during training is to use TensorBoard -- a browser-based application that you can run locally that provides you with:\n",
    "\n",
    "1. Live plots of the loss and metrics for training and evaluation\n",
    "2. (optionally) Visualizations of the histograms of your layer activations\n",
    "3. (optionally) 3D visualizations of the embedding spaces learned by your Embedding layers\n",
    "\n",
    "在训练过程中关注模型的最佳实践是使用TensorBoard函数：一个你可以在本地运行的基于浏览器的应用。这个应用可以为你提供：\n",
    "1. 为训练和验证过程绘制即时的损失和指标图像\n",
    "2. 有必要的话，可以提供激活函数的直方图\n",
    "3. 有需要的话，可以提供你的模型的潜入层的嵌入空间3D视图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have installed TensorFlow with pip, you should be able to launch TensorBoard from the command line:\n",
    "如果你已经通过pip方式安装了TensorFlow，你可以通过命令行激活TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard --logdir=/full_path_to_your_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the TensorBoard callback\n",
    "### 使用TensorBoard回调函数\n",
    "\n",
    "The easiest way to use TensorBoard with a Keras model and the fit() method is the TensorBoard callback.\n",
    "\n",
    "In the simplest case, just specify where you want the callback to write logs, and you're good to go:\n",
    "\n",
    "对于Keras模型和fit()方法而言，最便捷的调用TensorBoard的方式是使用TensorBoard回调函数\n",
    "\n",
    "在最简单的情况下，只需要指定在哪里通过回调函数记录日志就可以了："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.TensorBoard at 0x1dc894c8580>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.callbacks.TensorBoard(\n",
    "    log_dir=\"/full_path_to_your_logs\",\n",
    "    histogram_freq=0,  # How often to log histogram visualizations\n",
    "    embeddings_freq=0,  # How often to log embedding visualizations\n",
    "    update_freq=\"epoch\",\n",
    ")  # How often to write logs (default: once per epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information, see the documentation for the TensorBoard callback."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
